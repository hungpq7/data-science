{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Miscellaneous techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Common techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark; findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.enableHiveSupport().getOrCreate()\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>Year</th><th>Month</th><th>Product Name</th><th>Country Name</th><th>Month number</th><th>Value</th><th>Feature</th><th>Unit</th></tr>\n",
       "<tr><td>2010</td><td>January</td><td>SABLEFISH FRESH</td><td>UNITED ARAB EMIRATES</td><td>1</td><td>2297</td><td>EXP Quantity</td><td>kg</td></tr>\n",
       "<tr><td>2010</td><td>January</td><td>SABLEFISH FRESH</td><td>JAPAN</td><td>1</td><td>16025</td><td>EXP Quantity</td><td>kg</td></tr>\n",
       "<tr><td>2010</td><td>January</td><td>SABLEFISH FRESH</td><td>JAPAN</td><td>1</td><td>63437</td><td>EXP Quantity</td><td>kg</td></tr>\n",
       "<tr><td>2010</td><td>January</td><td>MONKFISH FRESH</td><td>CANADA</td><td>1</td><td>579</td><td>EXP Quantity</td><td>kg</td></tr>\n",
       "<tr><td>2010</td><td>January</td><td>MONKFISH FRESH</td><td>CANADA</td><td>1</td><td>7975</td><td>EXP Quantity</td><td>kg</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----+-------+---------------+--------------------+------------+-----+------------+----+\n",
       "|Year|  Month|   Product Name|        Country Name|Month number|Value|     Feature|Unit|\n",
       "+----+-------+---------------+--------------------+------------+-----+------------+----+\n",
       "|2010|January|SABLEFISH FRESH|UNITED ARAB EMIRATES|           1| 2297|EXP Quantity|  kg|\n",
       "|2010|January|SABLEFISH FRESH|               JAPAN|           1|16025|EXP Quantity|  kg|\n",
       "|2010|January|SABLEFISH FRESH|               JAPAN|           1|63437|EXP Quantity|  kg|\n",
       "|2010|January| MONKFISH FRESH|              CANADA|           1|  579|EXP Quantity|  kg|\n",
       "|2010|January| MONKFISH FRESH|              CANADA|           1| 7975|EXP Quantity|  kg|\n",
       "+----+-------+---------------+--------------------+------------+-----+------------+----+"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFish = spark.read.csv('data/us_fishery_trade.csv', header=True)\n",
    "dfFish.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>year</th><th>Month</th><th>Product Name</th><th>Country Name</th><th>Month number</th><th>Value</th><th>Feature</th><th>Unit</th></tr>\n",
       "<tr><td>2010</td><td>January</td><td>SABLEFISH FRESH</td><td>UNITED ARAB EMIRATES</td><td>1</td><td>2297</td><td>EXP Quantity</td><td>kg</td></tr>\n",
       "<tr><td>2010</td><td>January</td><td>SABLEFISH FRESH</td><td>JAPAN</td><td>1</td><td>16025</td><td>EXP Quantity</td><td>kg</td></tr>\n",
       "<tr><td>2010</td><td>January</td><td>SABLEFISH FRESH</td><td>JAPAN</td><td>1</td><td>63437</td><td>EXP Quantity</td><td>kg</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----+-------+---------------+--------------------+------------+-----+------------+----+\n",
       "|year|  Month|   Product Name|        Country Name|Month number|Value|     Feature|Unit|\n",
       "+----+-------+---------------+--------------------+------------+-----+------------+----+\n",
       "|2010|January|SABLEFISH FRESH|UNITED ARAB EMIRATES|           1| 2297|EXP Quantity|  kg|\n",
       "|2010|January|SABLEFISH FRESH|               JAPAN|           1|16025|EXP Quantity|  kg|\n",
       "|2010|January|SABLEFISH FRESH|               JAPAN|           1|63437|EXP Quantity|  kg|\n",
       "+----+-------+---------------+--------------------+------------+-----+------------+----+"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFish.withColumnRenamed('Year', 'year').limit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>year</th><th>month</th></tr>\n",
       "<tr><td>2010</td><td>January</td></tr>\n",
       "<tr><td>2010</td><td>January</td></tr>\n",
       "<tr><td>2010</td><td>January</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----+-------+\n",
       "|year|  month|\n",
       "+----+-------+\n",
       "|2010|January|\n",
       "|2010|January|\n",
       "|2010|January|\n",
       "+----+-------+"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFish.selectExpr('Year as year', 'Month as month').limit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>year</th><th>month</th><th>product_name</th><th>country_name</th><th>month_number</th><th>value</th><th>feature</th><th>unit</th></tr>\n",
       "<tr><td>2010</td><td>January</td><td>SABLEFISH FRESH</td><td>UNITED ARAB EMIRATES</td><td>1</td><td>2297</td><td>EXP Quantity</td><td>kg</td></tr>\n",
       "<tr><td>2010</td><td>January</td><td>SABLEFISH FRESH</td><td>JAPAN</td><td>1</td><td>16025</td><td>EXP Quantity</td><td>kg</td></tr>\n",
       "<tr><td>2010</td><td>January</td><td>SABLEFISH FRESH</td><td>JAPAN</td><td>1</td><td>63437</td><td>EXP Quantity</td><td>kg</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----+-------+---------------+--------------------+------------+-----+------------+----+\n",
       "|year|  month|   product_name|        country_name|month_number|value|     feature|unit|\n",
       "+----+-------+---------------+--------------------+------------+-----+------------+----+\n",
       "|2010|January|SABLEFISH FRESH|UNITED ARAB EMIRATES|           1| 2297|EXP Quantity|  kg|\n",
       "|2010|January|SABLEFISH FRESH|               JAPAN|           1|16025|EXP Quantity|  kg|\n",
       "|2010|January|SABLEFISH FRESH|               JAPAN|           1|63437|EXP Quantity|  kg|\n",
       "+----+-------+---------------+--------------------+------------+-----+------------+----+"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = [c.lower().replace(' ', '_') for c in dfFish.columns]\n",
    "dfFish.toDF(*column_names).limit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>year</th><th>month</th><th>product_name</th><th>country_name</th><th>month_number</th><th>value</th><th>feature</th><th>unit</th></tr>\n",
       "<tr><td>2010</td><td>January</td><td>SABLEFISH FRESH</td><td>UNITED ARAB EMIRATES</td><td>1</td><td>2297</td><td>EXP Quantity</td><td>kg</td></tr>\n",
       "<tr><td>2010</td><td>January</td><td>SABLEFISH FRESH</td><td>JAPAN</td><td>1</td><td>16025</td><td>EXP Quantity</td><td>kg</td></tr>\n",
       "<tr><td>2010</td><td>January</td><td>SABLEFISH FRESH</td><td>JAPAN</td><td>1</td><td>63437</td><td>EXP Quantity</td><td>kg</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----+-------+---------------+--------------------+------------+-----+------------+----+\n",
       "|year|  month|   product_name|        country_name|month_number|value|     feature|unit|\n",
       "+----+-------+---------------+--------------------+------------+-----+------------+----+\n",
       "|2010|January|SABLEFISH FRESH|UNITED ARAB EMIRATES|           1| 2297|EXP Quantity|  kg|\n",
       "|2010|January|SABLEFISH FRESH|               JAPAN|           1|16025|EXP Quantity|  kg|\n",
       "|2010|January|SABLEFISH FRESH|               JAPAN|           1|63437|EXP Quantity|  kg|\n",
       "+----+-------+---------------+--------------------+------------+-----+------------+----+"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFish.select([F.col(c).alias(c.lower().replace(' ', '_')) for c in dfFish.columns]).limit(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>crime_rate</th><th>land_rate</th><th>indus</th><th>chas</th><th>nox</th><th>room</th><th>age</th><th>distance</th><th>radial</th><th>tax</th><th>ptratio</th><th>black</th><th>lstat</th><th>price</th></tr>\n",
       "<tr><td>0.00632</td><td>18</td><td>2.31</td><td>0</td><td>0.538</td><td>6.575</td><td>65.2</td><td>4.09</td><td>1</td><td>296</td><td>15.3</td><td>396.9</td><td>4.98</td><td>24</td></tr>\n",
       "<tr><td>0.02731</td><td>0</td><td>7.07</td><td>0</td><td>0.469</td><td>6.421</td><td>78.9</td><td>4.9671</td><td>2</td><td>242</td><td>17.8</td><td>396.9</td><td>9.14</td><td>21.6</td></tr>\n",
       "<tr><td>0.02729</td><td>0</td><td>7.07</td><td>0</td><td>0.469</td><td>7.185</td><td>61.1</td><td>4.9671</td><td>2</td><td>242</td><td>17.8</td><td>392.83</td><td>4.03</td><td>34.7</td></tr>\n",
       "<tr><td>0.03237</td><td>0</td><td>2.18</td><td>0</td><td>0.458</td><td>6.998</td><td>45.8</td><td>6.0622</td><td>3</td><td>222</td><td>18.7</td><td>394.63</td><td>2.94</td><td>33.4</td></tr>\n",
       "<tr><td>0.06905</td><td>0</td><td>2.18</td><td>0</td><td>0.458</td><td>7.147</td><td>54.2</td><td>6.0622</td><td>3</td><td>222</td><td>18.7</td><td>396.9</td><td>5.33</td><td>36.2</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+---------+-----+----+-----+-----+----+--------+------+---+-------+------+-----+-----+\n",
       "|crime_rate|land_rate|indus|chas|  nox| room| age|distance|radial|tax|ptratio| black|lstat|price|\n",
       "+----------+---------+-----+----+-----+-----+----+--------+------+---+-------+------+-----+-----+\n",
       "|   0.00632|       18| 2.31|   0|0.538|6.575|65.2|    4.09|     1|296|   15.3| 396.9| 4.98|   24|\n",
       "|   0.02731|        0| 7.07|   0|0.469|6.421|78.9|  4.9671|     2|242|   17.8| 396.9| 9.14| 21.6|\n",
       "|   0.02729|        0| 7.07|   0|0.469|7.185|61.1|  4.9671|     2|242|   17.8|392.83| 4.03| 34.7|\n",
       "|   0.03237|        0| 2.18|   0|0.458|6.998|45.8|  6.0622|     3|222|   18.7|394.63| 2.94| 33.4|\n",
       "|   0.06905|        0| 2.18|   0|0.458|7.147|54.2|  6.0622|     3|222|   18.7| 396.9| 5.33| 36.2|\n",
       "+----------+---------+-----+----+-----+-----+----+--------+------+---+-------+------+-----+-----+"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfBoston = spark.read.csv('data/boston.csv', header=True)\n",
    "dfBoston.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>indus</th><th>chas</th><th>nox</th><th>room</th></tr>\n",
       "<tr><td>2.31</td><td>0</td><td>0.538</td><td>6.575</td></tr>\n",
       "<tr><td>7.07</td><td>0</td><td>0.469</td><td>6.421</td></tr>\n",
       "<tr><td>7.07</td><td>0</td><td>0.469</td><td>7.185</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----+----+-----+-----+\n",
       "|indus|chas|  nox| room|\n",
       "+-----+----+-----+-----+\n",
       "| 2.31|   0|0.538|6.575|\n",
       "| 7.07|   0|0.469|6.421|\n",
       "| 7.07|   0|0.469|7.185|\n",
       "+-----+----+-----+-----+"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['indus', 'chas', 'nox', 'room']\n",
    "dfBoston.select(columns).limit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>new_variable</th></tr>\n",
       "<tr><td>39.3</td></tr>\n",
       "<tr><td>39.4</td></tr>\n",
       "<tr><td>52.5</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------+\n",
       "|new_variable|\n",
       "+------------+\n",
       "|        39.3|\n",
       "|        39.4|\n",
       "|        52.5|\n",
       "+------------+"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfBoston.selectExpr('round(ptratio + price, 2) as new_variable').limit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>crime_rate</th><th>land_rate</th><th>indus</th><th>chas</th><th>nox</th><th>room</th><th>age</th></tr>\n",
       "<tr><td>0.00632</td><td>18</td><td>2.31</td><td>0</td><td>0.538</td><td>6.575</td><td>65.2</td></tr>\n",
       "<tr><td>0.02731</td><td>0</td><td>7.07</td><td>0</td><td>0.469</td><td>6.421</td><td>78.9</td></tr>\n",
       "<tr><td>0.02729</td><td>0</td><td>7.07</td><td>0</td><td>0.469</td><td>7.185</td><td>61.1</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+---------+-----+----+-----+-----+----+\n",
       "|crime_rate|land_rate|indus|chas|  nox| room| age|\n",
       "+----------+---------+-----+----+-----+-----+----+\n",
       "|   0.00632|       18| 2.31|   0|0.538|6.575|65.2|\n",
       "|   0.02731|        0| 7.07|   0|0.469|6.421|78.9|\n",
       "|   0.02729|        0| 7.07|   0|0.469|7.185|61.1|\n",
       "+----------+---------+-----+----+-----+-----+----+"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfBoston.drop('distance', 'radial', 'tax', 'ptratio', 'black', 'lstat', 'price').limit(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcting data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>video_id</th><th>trending_date</th><th>channel_title</th><th>category_id</th><th>publish_time</th><th>views</th><th>likes</th><th>dislikes</th><th>comment_count</th><th>comments_disabled</th><th>ratings_disabled</th></tr>\n",
       "<tr><td>2kyS6SvSYSE</td><td>2017-11-14</td><td>CaseyNeistat</td><td>22</td><td>2017-11-13T17:13:...</td><td>748374</td><td>57527</td><td>2966</td><td>15954</td><td>False</td><td>False</td></tr>\n",
       "<tr><td>1ZAPwfrtAFY</td><td>2017-11-14</td><td>LastWeekTonight</td><td>24</td><td>2017-11-13T07:30:...</td><td>2418783</td><td>97185</td><td>6146</td><td>12703</td><td>False</td><td>False</td></tr>\n",
       "<tr><td>5qpjK5DgCt4</td><td>2017-11-14</td><td>Rudy Mancuso</td><td>23</td><td>2017-11-12T19:05:...</td><td>3191434</td><td>146033</td><td>5339</td><td>8181</td><td>False</td><td>False</td></tr>\n",
       "<tr><td>puqaWrEC7tY</td><td>2017-11-14</td><td>Good Mythical Mor...</td><td>24</td><td>2017-11-13T11:00:...</td><td>343168</td><td>10172</td><td>666</td><td>2146</td><td>False</td><td>False</td></tr>\n",
       "<tr><td>d380meD0W0M</td><td>2017-11-14</td><td>nigahiga</td><td>24</td><td>2017-11-12T18:01:...</td><td>2095731</td><td>132235</td><td>1989</td><td>17518</td><td>False</td><td>False</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------+-------------+--------------------+-----------+--------------------+-------+------+--------+-------------+-----------------+----------------+\n",
       "|   video_id|trending_date|       channel_title|category_id|        publish_time|  views| likes|dislikes|comment_count|comments_disabled|ratings_disabled|\n",
       "+-----------+-------------+--------------------+-----------+--------------------+-------+------+--------+-------------+-----------------+----------------+\n",
       "|2kyS6SvSYSE|   2017-11-14|        CaseyNeistat|         22|2017-11-13T17:13:...| 748374| 57527|    2966|        15954|            False|           False|\n",
       "|1ZAPwfrtAFY|   2017-11-14|     LastWeekTonight|         24|2017-11-13T07:30:...|2418783| 97185|    6146|        12703|            False|           False|\n",
       "|5qpjK5DgCt4|   2017-11-14|        Rudy Mancuso|         23|2017-11-12T19:05:...|3191434|146033|    5339|         8181|            False|           False|\n",
       "|puqaWrEC7tY|   2017-11-14|Good Mythical Mor...|         24|2017-11-13T11:00:...| 343168| 10172|     666|         2146|            False|           False|\n",
       "|d380meD0W0M|   2017-11-14|            nigahiga|         24|2017-11-12T18:01:...|2095731|132235|    1989|        17518|            False|           False|\n",
       "+-----------+-------------+--------------------+-----------+--------------------+-------+------+--------+-------------+-----------------+----------------+"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfYoutube = spark.read.csv('data/youtube_trending.csv', header=True)\n",
    "dfYoutube.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>video_id</th><th>trending_date</th><th>channel_title</th><th>category_id</th><th>publish_time</th><th>views</th><th>likes</th><th>dislikes</th><th>comment_count</th><th>comments_disabled</th><th>ratings_disabled</th></tr>\n",
       "<tr><td>2kyS6SvSYSE</td><td>2017-11-14</td><td>CaseyNeistat</td><td>22</td><td>2017-11-14 00:13:01</td><td>748374</td><td>57527</td><td>2966</td><td>15954</td><td>false</td><td>false</td></tr>\n",
       "<tr><td>1ZAPwfrtAFY</td><td>2017-11-14</td><td>LastWeekTonight</td><td>24</td><td>2017-11-13 14:30:00</td><td>2418783</td><td>97185</td><td>6146</td><td>12703</td><td>false</td><td>false</td></tr>\n",
       "<tr><td>5qpjK5DgCt4</td><td>2017-11-14</td><td>Rudy Mancuso</td><td>23</td><td>2017-11-13 02:05:24</td><td>3191434</td><td>146033</td><td>5339</td><td>8181</td><td>false</td><td>false</td></tr>\n",
       "<tr><td>puqaWrEC7tY</td><td>2017-11-14</td><td>Good Mythical Mor...</td><td>24</td><td>2017-11-13 18:00:04</td><td>343168</td><td>10172</td><td>666</td><td>2146</td><td>false</td><td>false</td></tr>\n",
       "<tr><td>d380meD0W0M</td><td>2017-11-14</td><td>nigahiga</td><td>24</td><td>2017-11-13 01:01:41</td><td>2095731</td><td>132235</td><td>1989</td><td>17518</td><td>false</td><td>false</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------+-------------+--------------------+-----------+-------------------+-------+------+--------+-------------+-----------------+----------------+\n",
       "|   video_id|trending_date|       channel_title|category_id|       publish_time|  views| likes|dislikes|comment_count|comments_disabled|ratings_disabled|\n",
       "+-----------+-------------+--------------------+-----------+-------------------+-------+------+--------+-------------+-----------------+----------------+\n",
       "|2kyS6SvSYSE|   2017-11-14|        CaseyNeistat|         22|2017-11-14 00:13:01| 748374| 57527|    2966|        15954|            false|           false|\n",
       "|1ZAPwfrtAFY|   2017-11-14|     LastWeekTonight|         24|2017-11-13 14:30:00|2418783| 97185|    6146|        12703|            false|           false|\n",
       "|5qpjK5DgCt4|   2017-11-14|        Rudy Mancuso|         23|2017-11-13 02:05:24|3191434|146033|    5339|         8181|            false|           false|\n",
       "|puqaWrEC7tY|   2017-11-14|Good Mythical Mor...|         24|2017-11-13 18:00:04| 343168| 10172|     666|         2146|            false|           false|\n",
       "|d380meD0W0M|   2017-11-14|            nigahiga|         24|2017-11-13 01:01:41|2095731|132235|    1989|        17518|            false|           false|\n",
       "+-----------+-------------+--------------------+-----------+-------------------+-------+------+--------+-------------+-----------------+----------------+"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfYoutube\\\n",
    "    .withColumn('trending_date', F.to_date('trending_date'))\\\n",
    "    .withColumn('publish_time', F.to_timestamp('publish_time'))\\\n",
    "    .withColumn('category_id', F.col('category_id').cast('int'))\\\n",
    "    .withColumn('views', F.col('views').cast('int'))\\\n",
    "    .withColumn('likes', F.col('likes').cast('int'))\\\n",
    "    .withColumn('dislikes', F.col('dislikes').cast('int'))\\\n",
    "    .withColumn('comment_count', F.col('comment_count').cast('int'))\\\n",
    "    .withColumn('comments_disabled', F.col('comments_disabled').cast('boolean'))\\\n",
    "    .withColumn('ratings_disabled', F.col('ratings_disabled').cast('boolean'))\\\n",
    "    .limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Text manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark; findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.enableHiveSupport().getOrCreate()\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>invoice_id</th><th>brand</th><th>city</th><th>customer_type</th><th>gender</th><th>product_line</th><th>unit_price</th><th>quantity</th><th>tax</th><th>date</th><th>time</th><th>payment</th><th>cost</th><th>gross_margin_percentage</th><th>profit</th><th>rating</th></tr>\n",
       "<tr><td>750-67-8428</td><td>A</td><td>Yangon</td><td>Member</td><td>Female</td><td>Health and beauty</td><td>74.69</td><td>7</td><td>26.1415</td><td>01/05/2019</td><td>13:08</td><td>Ewallet</td><td>522.83</td><td>4.761904762</td><td>26.1415</td><td>9.1</td></tr>\n",
       "<tr><td>226-31-3081</td><td>C</td><td>Naypyitaw</td><td>Normal</td><td>Female</td><td>Electronic access...</td><td>15.28</td><td>5</td><td>3.82</td><td>03/08/2019</td><td>10:29</td><td>Cash</td><td>76.4</td><td>4.761904762</td><td>3.82</td><td>9.6</td></tr>\n",
       "<tr><td>631-41-3108</td><td>A</td><td>Yangon</td><td>Normal</td><td>Male</td><td>Home and lifestyle</td><td>46.33</td><td>7</td><td>16.2155</td><td>03/03/2019</td><td>13:23</td><td>Credit card</td><td>324.31</td><td>4.761904762</td><td>16.2155</td><td>7.4</td></tr>\n",
       "<tr><td>123-19-1176</td><td>A</td><td>Yangon</td><td>Member</td><td>Male</td><td>Health and beauty</td><td>58.22</td><td>8</td><td>23.288</td><td>1/27/2019</td><td>20:33</td><td>Ewallet</td><td>465.76</td><td>4.761904762</td><td>23.288</td><td>8.4</td></tr>\n",
       "<tr><td>373-73-7910</td><td>A</td><td>Yangon</td><td>Normal</td><td>Male</td><td>Sports and travel</td><td>86.31</td><td>7</td><td>30.2085</td><td>02/08/2019</td><td>10:37</td><td>Ewallet</td><td>604.17</td><td>4.761904762</td><td>30.2085</td><td>5.3</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------+-----+---------+-------------+------+--------------------+----------+--------+-------+----------+-----+-----------+------+-----------------------+-------+------+\n",
       "| invoice_id|brand|     city|customer_type|gender|        product_line|unit_price|quantity|    tax|      date| time|    payment|  cost|gross_margin_percentage| profit|rating|\n",
       "+-----------+-----+---------+-------------+------+--------------------+----------+--------+-------+----------+-----+-----------+------+-----------------------+-------+------+\n",
       "|750-67-8428|    A|   Yangon|       Member|Female|   Health and beauty|     74.69|       7|26.1415|01/05/2019|13:08|    Ewallet|522.83|            4.761904762|26.1415|   9.1|\n",
       "|226-31-3081|    C|Naypyitaw|       Normal|Female|Electronic access...|     15.28|       5|   3.82|03/08/2019|10:29|       Cash|  76.4|            4.761904762|   3.82|   9.6|\n",
       "|631-41-3108|    A|   Yangon|       Normal|  Male|  Home and lifestyle|     46.33|       7|16.2155|03/03/2019|13:23|Credit card|324.31|            4.761904762|16.2155|   7.4|\n",
       "|123-19-1176|    A|   Yangon|       Member|  Male|   Health and beauty|     58.22|       8| 23.288| 1/27/2019|20:33|    Ewallet|465.76|            4.761904762| 23.288|   8.4|\n",
       "|373-73-7910|    A|   Yangon|       Normal|  Male|   Sports and travel|     86.31|       7|30.2085|02/08/2019|10:37|    Ewallet|604.17|            4.761904762|30.2085|   5.3|\n",
       "+-----------+-----+---------+-------------+------+--------------------+----------+--------+-------+----------+-----+-----------+------+-----------------------+-------+------+"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSupermarket = spark.read.csv('data/supermarket_sales.csv', header=True)\n",
    "dfSupermarket.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting substrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>invoice_id</th><th>first_part</th><th>second_part</th><th>third_part</th></tr>\n",
       "<tr><td>750-67-8428</td><td>750</td><td>67</td><td>8428</td></tr>\n",
       "<tr><td>226-31-3081</td><td>226</td><td>31</td><td>3081</td></tr>\n",
       "<tr><td>631-41-3108</td><td>631</td><td>41</td><td>3108</td></tr>\n",
       "<tr><td>123-19-1176</td><td>123</td><td>19</td><td>1176</td></tr>\n",
       "<tr><td>373-73-7910</td><td>373</td><td>73</td><td>7910</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------+----------+-----------+----------+\n",
       "| invoice_id|first_part|second_part|third_part|\n",
       "+-----------+----------+-----------+----------+\n",
       "|750-67-8428|       750|         67|      8428|\n",
       "|226-31-3081|       226|         31|      3081|\n",
       "|631-41-3108|       631|         41|      3108|\n",
       "|123-19-1176|       123|         19|      1176|\n",
       "|373-73-7910|       373|         73|      7910|\n",
       "+-----------+----------+-----------+----------+"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoice_id = F.split('invoice_id', pattern='-')\n",
    "dfSupermarket\\\n",
    "    .select('invoice_id')\\\n",
    "    .withColumn('first_part', invoice_id.getItem(0))\\\n",
    "    .withColumn('second_part', invoice_id.getItem(1))\\\n",
    "    .withColumn('third_part', invoice_id.getItem(2))\\\n",
    "    .limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>city</th><th>substring(city, 0, 4)</th></tr>\n",
       "<tr><td>Yangon</td><td>Yang</td></tr>\n",
       "<tr><td>Naypyitaw</td><td>Nayp</td></tr>\n",
       "<tr><td>Yangon</td><td>Yang</td></tr>\n",
       "<tr><td>Yangon</td><td>Yang</td></tr>\n",
       "<tr><td>Yangon</td><td>Yang</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------+---------------------+\n",
       "|     city|substring(city, 0, 4)|\n",
       "+---------+---------------------+\n",
       "|   Yangon|                 Yang|\n",
       "|Naypyitaw|                 Nayp|\n",
       "|   Yangon|                 Yang|\n",
       "|   Yangon|                 Yang|\n",
       "|   Yangon|                 Yang|\n",
       "+---------+---------------------+"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSupermarket.select('city', F.substring('city', 0, 4)).limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>concat(customer_type, , , gender)</th></tr>\n",
       "<tr><td>Member, Female</td></tr>\n",
       "<tr><td>Normal, Female</td></tr>\n",
       "<tr><td>Normal, Male</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------------------------------+\n",
       "|concat(customer_type, , , gender)|\n",
       "+---------------------------------+\n",
       "|                   Member, Female|\n",
       "|                   Normal, Female|\n",
       "|                     Normal, Male|\n",
       "+---------------------------------+"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSupermarket.select(F.concat('customer_type', F.lit(', '), 'gender')).limit(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>upper(city)</th></tr>\n",
       "<tr><td>YANGON</td></tr>\n",
       "<tr><td>NAYPYITAW</td></tr>\n",
       "<tr><td>YANGON</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------+\n",
       "|upper(city)|\n",
       "+-----------+\n",
       "|     YANGON|\n",
       "|  NAYPYITAW|\n",
       "|     YANGON|\n",
       "+-----------+"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSupermarket.select(F.upper('city')).limit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>initcap(product_line)</th></tr>\n",
       "<tr><td>Health And Beauty</td></tr>\n",
       "<tr><td>Electronic Access...</td></tr>\n",
       "<tr><td>Home And Lifestyle</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------------------+\n",
       "|initcap(product_line)|\n",
       "+---------------------+\n",
       "|    Health And Beauty|\n",
       "| Electronic Access...|\n",
       "|   Home And Lifestyle|\n",
       "+---------------------+"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSupermarket.select(F.initcap('product_line')).limit(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>lpad(city, 9, *)</th></tr>\n",
       "<tr><td>Naypyitaw</td></tr>\n",
       "<tr><td>*Mandalay</td></tr>\n",
       "<tr><td>***Yangon</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------------+\n",
       "|lpad(city, 9, *)|\n",
       "+----------------+\n",
       "|       Naypyitaw|\n",
       "|       *Mandalay|\n",
       "|       ***Yangon|\n",
       "+----------------+"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSupermarket.select('city').distinct().select(F.lpad('city', len=9, pad='*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>rpad(city, 9, *)</th></tr>\n",
       "<tr><td>Naypyitaw</td></tr>\n",
       "<tr><td>Mandalay*</td></tr>\n",
       "<tr><td>Yangon***</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------------+\n",
       "|rpad(city, 9, *)|\n",
       "+----------------+\n",
       "|       Naypyitaw|\n",
       "|       Mandalay*|\n",
       "|       Yangon***|\n",
       "+----------------+"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSupermarket.select('city').distinct().select(F.rpad('city', len=9, pad='*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trimming\n",
    "PySpark supports \n",
    "<code style='font-size:13px;'>trim()</code>, \n",
    "<code style='font-size:13px;'>ltrim()</code> and \n",
    "<code style='font-size:13px;'>rtrim()</code> functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>count(DISTINCT country)</th></tr>\n",
       "<tr><td>3</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------------------+\n",
       "|count(DISTINCT country)|\n",
       "+-----------------------+\n",
       "|                      3|\n",
       "+-----------------------+"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.createDataFrame(\n",
    "    data=[['United Kingdom'], [' United Kingdom'], ['United Kingdom ']],\n",
    "    schema=['country'])\n",
    "df.select(F.countDistinct('country'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>count(DISTINCT country)</th></tr>\n",
       "<tr><td>1</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------------------+\n",
       "|count(DISTINCT country)|\n",
       "+-----------------------+\n",
       "|                      1|\n",
       "+-----------------------+"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(F.trim('country').alias('country')).select(F.countDistinct('country'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>product_line</th><th>product_line_new</th></tr>\n",
       "<tr><td>Home and lifestyle</td><td>Home_and_lifestyle</td></tr>\n",
       "<tr><td>Fashion accessories</td><td>Fashion_accessories</td></tr>\n",
       "<tr><td>Health and beauty</td><td>Health_and_beauty</td></tr>\n",
       "<tr><td>Electronic access...</td><td>Electronic_access...</td></tr>\n",
       "<tr><td>Food and beverages</td><td>Food_and_beverages</td></tr>\n",
       "<tr><td>Sports and travel</td><td>Sports_and_travel</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+--------------------+\n",
       "|        product_line|    product_line_new|\n",
       "+--------------------+--------------------+\n",
       "|  Home and lifestyle|  Home_and_lifestyle|\n",
       "| Fashion accessories| Fashion_accessories|\n",
       "|   Health and beauty|   Health_and_beauty|\n",
       "|Electronic access...|Electronic_access...|\n",
       "|  Food and beverages|  Food_and_beverages|\n",
       "|   Sports and travel|   Sports_and_travel|\n",
       "+--------------------+--------------------+"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSupermarket\\\n",
    "    .select('product_line').distinct()\\\n",
    "    .withColumn('product_line_new', F.regexp_replace('product_line', pattern=' ', replacement='_'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>product_line</th></tr>\n",
       "<tr><td>Fashion accessories</td></tr>\n",
       "<tr><td>Electronic access...</td></tr>\n",
       "<tr><td>Food and beverages</td></tr>\n",
       "<tr><td>Sports and travel</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+\n",
       "|        product_line|\n",
       "+--------------------+\n",
       "| Fashion accessories|\n",
       "|Electronic access...|\n",
       "|  Food and beverages|\n",
       "|   Sports and travel|\n",
       "+--------------------+"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSupermarket.select('product_line').distinct().where(~F.col('product_line').contains('ty'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Date manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark; findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.enableHiveSupport().getOrCreate()\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>video_id</th><th>trending_date</th><th>channel_title</th><th>category_id</th><th>publish_time</th><th>views</th><th>likes</th><th>dislikes</th><th>comment_count</th><th>comments_disabled</th><th>ratings_disabled</th></tr>\n",
       "<tr><td>2kyS6SvSYSE</td><td>2017-11-14</td><td>CaseyNeistat</td><td>22</td><td>2017-11-13T17:13:...</td><td>748374</td><td>57527</td><td>2966</td><td>15954</td><td>False</td><td>False</td></tr>\n",
       "<tr><td>1ZAPwfrtAFY</td><td>2017-11-14</td><td>LastWeekTonight</td><td>24</td><td>2017-11-13T07:30:...</td><td>2418783</td><td>97185</td><td>6146</td><td>12703</td><td>False</td><td>False</td></tr>\n",
       "<tr><td>5qpjK5DgCt4</td><td>2017-11-14</td><td>Rudy Mancuso</td><td>23</td><td>2017-11-12T19:05:...</td><td>3191434</td><td>146033</td><td>5339</td><td>8181</td><td>False</td><td>False</td></tr>\n",
       "<tr><td>puqaWrEC7tY</td><td>2017-11-14</td><td>Good Mythical Mor...</td><td>24</td><td>2017-11-13T11:00:...</td><td>343168</td><td>10172</td><td>666</td><td>2146</td><td>False</td><td>False</td></tr>\n",
       "<tr><td>d380meD0W0M</td><td>2017-11-14</td><td>nigahiga</td><td>24</td><td>2017-11-12T18:01:...</td><td>2095731</td><td>132235</td><td>1989</td><td>17518</td><td>False</td><td>False</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------+-------------+--------------------+-----------+--------------------+-------+------+--------+-------------+-----------------+----------------+\n",
       "|   video_id|trending_date|       channel_title|category_id|        publish_time|  views| likes|dislikes|comment_count|comments_disabled|ratings_disabled|\n",
       "+-----------+-------------+--------------------+-----------+--------------------+-------+------+--------+-------------+-----------------+----------------+\n",
       "|2kyS6SvSYSE|   2017-11-14|        CaseyNeistat|         22|2017-11-13T17:13:...| 748374| 57527|    2966|        15954|            False|           False|\n",
       "|1ZAPwfrtAFY|   2017-11-14|     LastWeekTonight|         24|2017-11-13T07:30:...|2418783| 97185|    6146|        12703|            False|           False|\n",
       "|5qpjK5DgCt4|   2017-11-14|        Rudy Mancuso|         23|2017-11-12T19:05:...|3191434|146033|    5339|         8181|            False|           False|\n",
       "|puqaWrEC7tY|   2017-11-14|Good Mythical Mor...|         24|2017-11-13T11:00:...| 343168| 10172|     666|         2146|            False|           False|\n",
       "|d380meD0W0M|   2017-11-14|            nigahiga|         24|2017-11-12T18:01:...|2095731|132235|    1989|        17518|            False|           False|\n",
       "+-----------+-------------+--------------------+-----------+--------------------+-------+------+--------+-------------+-----------------+----------------+"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfYoutube = spark.read.csv('data/youtube_trending.csv', header=True)\n",
    "dfYoutube.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The standard datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>trending_date</th><th>publish_time</th></tr>\n",
       "<tr><td>2017-11-14</td><td>2017-11-09 04:50:37</td></tr>\n",
       "<tr><td>2017-11-15</td><td>2017-11-14 07:45:15</td></tr>\n",
       "<tr><td>2017-11-15</td><td>2017-11-14 03:47:49</td></tr>\n",
       "<tr><td>2017-11-16</td><td>2017-11-14 03:00:01</td></tr>\n",
       "<tr><td>2017-11-18</td><td>2017-11-13 21:44:24</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------------+-------------------+\n",
       "|trending_date|       publish_time|\n",
       "+-------------+-------------------+\n",
       "|   2017-11-14|2017-11-09 04:50:37|\n",
       "|   2017-11-15|2017-11-14 07:45:15|\n",
       "|   2017-11-15|2017-11-14 03:47:49|\n",
       "|   2017-11-16|2017-11-14 03:00:01|\n",
       "|   2017-11-18|2017-11-13 21:44:24|\n",
       "+-------------+-------------------+"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfYoutube = dfYoutube\\\n",
    "    .withColumn('trending_date', F.to_date('trending_date'))\\\n",
    "    .withColumn('publish_time', F.to_timestamp('publish_time'))\n",
    "dfYoutube.select('trending_date', 'publish_time').distinct().limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unix timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>unix_publish_time</th></tr>\n",
       "<tr><td>1510593181</td></tr>\n",
       "<tr><td>1510558200</td></tr>\n",
       "<tr><td>1510513524</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------------+\n",
       "|unix_publish_time|\n",
       "+-----------------+\n",
       "|       1510593181|\n",
       "|       1510558200|\n",
       "|       1510513524|\n",
       "+-----------------+"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfYoutube.select(F.unix_timestamp('publish_time').alias('unix_publish_time')).limit(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting date part\n",
    "*Reference: [Spark - Datetime patterns](https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>publish_time</th><th>year</th><th>quarter</th><th>week</th></tr>\n",
       "<tr><td>2017-11-14 00:13:01</td><td>2017</td><td>2017-4</td><td>2017-46</td></tr>\n",
       "<tr><td>2017-11-13 14:30:00</td><td>2017</td><td>2017-4</td><td>2017-46</td></tr>\n",
       "<tr><td>2017-11-13 02:05:24</td><td>2017</td><td>2017-4</td><td>2017-46</td></tr>\n",
       "<tr><td>2017-11-13 18:00:04</td><td>2017</td><td>2017-4</td><td>2017-46</td></tr>\n",
       "<tr><td>2017-11-13 01:01:41</td><td>2017</td><td>2017-4</td><td>2017-46</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------------------+----+-------+-------+\n",
       "|       publish_time|year|quarter|   week|\n",
       "+-------------------+----+-------+-------+\n",
       "|2017-11-14 00:13:01|2017| 2017-4|2017-46|\n",
       "|2017-11-13 14:30:00|2017| 2017-4|2017-46|\n",
       "|2017-11-13 02:05:24|2017| 2017-4|2017-46|\n",
       "|2017-11-13 18:00:04|2017| 2017-4|2017-46|\n",
       "|2017-11-13 01:01:41|2017| 2017-4|2017-46|\n",
       "+-------------------+----+-------+-------+"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfYoutube.select(\n",
    "    F.col('publish_time'),\n",
    "    F.date_format('publish_time', 'yyyy').alias('year'),\n",
    "    F.date_format('publish_time', 'yyyy-q').alias('quarter'),\n",
    "    F.concat(F.year('publish_time'), F.lit('-'), F.weekofyear('publish_time')).alias('week'),\n",
    ").limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting cyclic attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>publish_time</th><th>year</th><th>quarter</th><th>month</th><th>month_name</th><th>week_of_year</th><th>day_of_year</th><th>day</th><th>weekday</th><th>hour</th><th>minute</th><th>second</th></tr>\n",
       "<tr><td>2017-11-14 00:13:01</td><td>2017</td><td>4</td><td>11</td><td>November</td><td>46</td><td>318</td><td>14</td><td>Tuesday</td><td>0</td><td>13</td><td>1</td></tr>\n",
       "<tr><td>2017-11-13 14:30:00</td><td>2017</td><td>4</td><td>11</td><td>November</td><td>46</td><td>317</td><td>13</td><td>Monday</td><td>14</td><td>30</td><td>0</td></tr>\n",
       "<tr><td>2017-11-13 02:05:24</td><td>2017</td><td>4</td><td>11</td><td>November</td><td>46</td><td>317</td><td>13</td><td>Monday</td><td>2</td><td>5</td><td>24</td></tr>\n",
       "<tr><td>2017-11-13 18:00:04</td><td>2017</td><td>4</td><td>11</td><td>November</td><td>46</td><td>317</td><td>13</td><td>Monday</td><td>18</td><td>0</td><td>4</td></tr>\n",
       "<tr><td>2017-11-13 01:01:41</td><td>2017</td><td>4</td><td>11</td><td>November</td><td>46</td><td>317</td><td>13</td><td>Monday</td><td>1</td><td>1</td><td>41</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------------------+----+-------+-----+----------+------------+-----------+---+-------+----+------+------+\n",
       "|       publish_time|year|quarter|month|month_name|week_of_year|day_of_year|day|weekday|hour|minute|second|\n",
       "+-------------------+----+-------+-----+----------+------------+-----------+---+-------+----+------+------+\n",
       "|2017-11-14 00:13:01|2017|      4|   11|  November|          46|        318| 14|Tuesday|   0|    13|     1|\n",
       "|2017-11-13 14:30:00|2017|      4|   11|  November|          46|        317| 13| Monday|  14|    30|     0|\n",
       "|2017-11-13 02:05:24|2017|      4|   11|  November|          46|        317| 13| Monday|   2|     5|    24|\n",
       "|2017-11-13 18:00:04|2017|      4|   11|  November|          46|        317| 13| Monday|  18|     0|     4|\n",
       "|2017-11-13 01:01:41|2017|      4|   11|  November|          46|        317| 13| Monday|   1|     1|    41|\n",
       "+-------------------+----+-------+-----+----------+------------+-----------+---+-------+----+------+------+"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfYoutube.select(\n",
    "    F.col('publish_time'),\n",
    "    F.year('publish_time').alias('year'),\n",
    "    F.quarter('publish_time').alias('quarter'),\n",
    "    F.month('publish_time').alias('month'),\n",
    "    F.date_format('publish_time', 'MMMM').alias('month_name'),\n",
    "    F.weekofyear('publish_time').alias('week_of_year'),\n",
    "    F.dayofyear('publish_time').alias('day_of_year'),\n",
    "    F.dayofmonth('publish_time').alias('day'),\n",
    "    F.date_format('publish_time', 'EEEE').alias('weekday'),\n",
    "    F.hour('publish_time').alias('hour'),\n",
    "    F.minute('publish_time').alias('minute'),\n",
    "    F.second('publish_time').alias('second'),\n",
    ").limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rounding date\n",
    "PySpark allows rounding datetime using the <code style='font-size:13px;'>date_trunc()</code> function with specifics values of the\n",
    "<code style='font-size:13px;'>format</code> parameter:\n",
    "<code style='font-size:13px;'>year</code>\n",
    "<code style='font-size:13px;'>quarter</code>\n",
    "<code style='font-size:13px;'>month</code>\n",
    "<code style='font-size:13px;'>day</code>\n",
    "<code style='font-size:13px;'>hour</code>\n",
    "<code style='font-size:13px;'>minute</code>\n",
    "<code style='font-size:13px;'>second</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>date_trunc(day, publish_time)</th></tr>\n",
       "<tr><td>2017-11-05 00:00:00</td></tr>\n",
       "<tr><td>2016-06-20 00:00:00</td></tr>\n",
       "<tr><td>2017-10-21 00:00:00</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------------------------+\n",
       "|date_trunc(day, publish_time)|\n",
       "+-----------------------------+\n",
       "|          2017-11-05 00:00:00|\n",
       "|          2016-06-20 00:00:00|\n",
       "|          2017-10-21 00:00:00|\n",
       "+-----------------------------+"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfYoutube.select(F.date_trunc(format='day', timestamp='publish_time')).distinct().limit(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>video_id</th><th>trending_date</th><th>channel_title</th><th>category_id</th><th>publish_time</th><th>views</th><th>likes</th><th>dislikes</th><th>comment_count</th><th>comments_disabled</th><th>ratings_disabled</th></tr>\n",
       "<tr><td>2kyS6SvSYSE</td><td>2017-11-14</td><td>CaseyNeistat</td><td>22</td><td>2017-11-14 00:13:01</td><td>748374</td><td>57527</td><td>2966</td><td>15954</td><td>False</td><td>False</td></tr>\n",
       "<tr><td>1ZAPwfrtAFY</td><td>2017-11-14</td><td>LastWeekTonight</td><td>24</td><td>2017-11-13 14:30:00</td><td>2418783</td><td>97185</td><td>6146</td><td>12703</td><td>False</td><td>False</td></tr>\n",
       "<tr><td>5qpjK5DgCt4</td><td>2017-11-14</td><td>Rudy Mancuso</td><td>23</td><td>2017-11-13 02:05:24</td><td>3191434</td><td>146033</td><td>5339</td><td>8181</td><td>False</td><td>False</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------+-------------+---------------+-----------+-------------------+-------+------+--------+-------------+-----------------+----------------+\n",
       "|   video_id|trending_date|  channel_title|category_id|       publish_time|  views| likes|dislikes|comment_count|comments_disabled|ratings_disabled|\n",
       "+-----------+-------------+---------------+-----------+-------------------+-------+------+--------+-------------+-----------------+----------------+\n",
       "|2kyS6SvSYSE|   2017-11-14|   CaseyNeistat|         22|2017-11-14 00:13:01| 748374| 57527|    2966|        15954|            False|           False|\n",
       "|1ZAPwfrtAFY|   2017-11-14|LastWeekTonight|         24|2017-11-13 14:30:00|2418783| 97185|    6146|        12703|            False|           False|\n",
       "|5qpjK5DgCt4|   2017-11-14|   Rudy Mancuso|         23|2017-11-13 02:05:24|3191434|146033|    5339|         8181|            False|           False|\n",
       "+-----------+-------------+---------------+-----------+-------------------+-------+------+--------+-------------+-----------------+----------------+"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfYoutube.limit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>trending_date</th><th>days_to_now</th></tr>\n",
       "<tr><td>2017-12-27</td><td>1308</td></tr>\n",
       "<tr><td>2017-11-28</td><td>1337</td></tr>\n",
       "<tr><td>2017-11-22</td><td>1343</td></tr>\n",
       "<tr><td>2017-12-25</td><td>1310</td></tr>\n",
       "<tr><td>2017-11-17</td><td>1348</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------------+-----------+\n",
       "|trending_date|days_to_now|\n",
       "+-------------+-----------+\n",
       "|   2017-12-27|       1308|\n",
       "|   2017-11-28|       1337|\n",
       "|   2017-11-22|       1343|\n",
       "|   2017-12-25|       1310|\n",
       "|   2017-11-17|       1348|\n",
       "+-------------+-----------+"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfYoutube.select(\n",
    "    'trending_date',\n",
    "    F.datediff(F.current_date(), F.col('trending_date')).alias('days_to_now')\n",
    ").distinct().limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>trending_date</th><th>20_days_ealier</th></tr>\n",
       "<tr><td>2017-12-11</td><td>2017-11-21</td></tr>\n",
       "<tr><td>2017-12-03</td><td>2017-11-13</td></tr>\n",
       "<tr><td>2017-12-17</td><td>2017-11-27</td></tr>\n",
       "<tr><td>2017-11-30</td><td>2017-11-10</td></tr>\n",
       "<tr><td>2017-11-14</td><td>2017-10-25</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------------+--------------+\n",
       "|trending_date|20_days_ealier|\n",
       "+-------------+--------------+\n",
       "|   2017-12-11|    2017-11-21|\n",
       "|   2017-12-03|    2017-11-13|\n",
       "|   2017-12-17|    2017-11-27|\n",
       "|   2017-11-30|    2017-11-10|\n",
       "|   2017-11-14|    2017-10-25|\n",
       "+-------------+--------------+"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfYoutube.select(\n",
    "    'trending_date',\n",
    "    F.date_add(F.col('trending_date'), days=-20).alias('20_days_ealier')\n",
    ").distinct().limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>trending_date</th><th>same_day_next_year</th></tr>\n",
       "<tr><td>2017-12-06</td><td>2018-12-06</td></tr>\n",
       "<tr><td>2017-12-23</td><td>2018-12-23</td></tr>\n",
       "<tr><td>2017-12-07</td><td>2018-12-07</td></tr>\n",
       "<tr><td>2017-12-17</td><td>2018-12-17</td></tr>\n",
       "<tr><td>2017-11-14</td><td>2018-11-14</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------------+------------------+\n",
       "|trending_date|same_day_next_year|\n",
       "+-------------+------------------+\n",
       "|   2017-12-06|        2018-12-06|\n",
       "|   2017-12-23|        2018-12-23|\n",
       "|   2017-12-07|        2018-12-07|\n",
       "|   2017-12-17|        2018-12-17|\n",
       "|   2017-11-14|        2018-11-14|\n",
       "+-------------+------------------+"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfYoutube.select(\n",
    "    'trending_date',\n",
    "    F.add_months(F.col('trending_date'), months=12).alias('same_day_next_year')\n",
    ").distinct().limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Numerical functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark; findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.enableHiveSupport().getOrCreate()\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>video_id</th><th>trending_date</th><th>channel_title</th><th>category_id</th><th>publish_time</th><th>views</th><th>likes</th><th>dislikes</th><th>comment_count</th><th>comments_disabled</th><th>ratings_disabled</th></tr>\n",
       "<tr><td>2kyS6SvSYSE</td><td>2017-11-14</td><td>CaseyNeistat</td><td>22</td><td>2017-11-13T17:13:...</td><td>748374</td><td>57527</td><td>2966</td><td>15954</td><td>False</td><td>False</td></tr>\n",
       "<tr><td>1ZAPwfrtAFY</td><td>2017-11-14</td><td>LastWeekTonight</td><td>24</td><td>2017-11-13T07:30:...</td><td>2418783</td><td>97185</td><td>6146</td><td>12703</td><td>False</td><td>False</td></tr>\n",
       "<tr><td>5qpjK5DgCt4</td><td>2017-11-14</td><td>Rudy Mancuso</td><td>23</td><td>2017-11-12T19:05:...</td><td>3191434</td><td>146033</td><td>5339</td><td>8181</td><td>False</td><td>False</td></tr>\n",
       "<tr><td>puqaWrEC7tY</td><td>2017-11-14</td><td>Good Mythical Mor...</td><td>24</td><td>2017-11-13T11:00:...</td><td>343168</td><td>10172</td><td>666</td><td>2146</td><td>False</td><td>False</td></tr>\n",
       "<tr><td>d380meD0W0M</td><td>2017-11-14</td><td>nigahiga</td><td>24</td><td>2017-11-12T18:01:...</td><td>2095731</td><td>132235</td><td>1989</td><td>17518</td><td>False</td><td>False</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------+-------------+--------------------+-----------+--------------------+-------+------+--------+-------------+-----------------+----------------+\n",
       "|   video_id|trending_date|       channel_title|category_id|        publish_time|  views| likes|dislikes|comment_count|comments_disabled|ratings_disabled|\n",
       "+-----------+-------------+--------------------+-----------+--------------------+-------+------+--------+-------------+-----------------+----------------+\n",
       "|2kyS6SvSYSE|   2017-11-14|        CaseyNeistat|         22|2017-11-13T17:13:...| 748374| 57527|    2966|        15954|            False|           False|\n",
       "|1ZAPwfrtAFY|   2017-11-14|     LastWeekTonight|         24|2017-11-13T07:30:...|2418783| 97185|    6146|        12703|            False|           False|\n",
       "|5qpjK5DgCt4|   2017-11-14|        Rudy Mancuso|         23|2017-11-12T19:05:...|3191434|146033|    5339|         8181|            False|           False|\n",
       "|puqaWrEC7tY|   2017-11-14|Good Mythical Mor...|         24|2017-11-13T11:00:...| 343168| 10172|     666|         2146|            False|           False|\n",
       "|d380meD0W0M|   2017-11-14|            nigahiga|         24|2017-11-12T18:01:...|2095731|132235|    1989|        17518|            False|           False|\n",
       "+-----------+-------------+--------------------+-----------+--------------------+-------+------+--------+-------------+-----------------+----------------+"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfYoutube = spark.read.csv('data/youtube_trending.csv', header=True)\n",
    "dfYoutube.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>likes</th><th>CAST(round(likes, -3) AS INT)</th></tr>\n",
       "<tr><td>57527</td><td>58000</td></tr>\n",
       "<tr><td>97185</td><td>97000</td></tr>\n",
       "<tr><td>146033</td><td>146000</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+-----------------------------+\n",
       "| likes|CAST(round(likes, -3) AS INT)|\n",
       "+------+-----------------------------+\n",
       "| 57527|                        58000|\n",
       "| 97185|                        97000|\n",
       "|146033|                       146000|\n",
       "+------+-----------------------------+"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfYoutube.select('likes', F.round('likes', -3).cast('int')).limit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>max(likes)</th></tr>\n",
       "<tr><td>99980</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+\n",
       "|max(likes)|\n",
       "+----------+\n",
       "|     99980|\n",
       "+----------+"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfYoutube.select(F.max('likes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>sum(likes)</th></tr>\n",
       "<tr><td>4.68961011E8</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------+\n",
       "|  sum(likes)|\n",
       "+------------+\n",
       "|4.68961011E8|\n",
       "+------------+"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfYoutube.select(F.sum('likes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>likes</th><th>CAST(CBRT(likes) AS INT)</th></tr>\n",
       "<tr><td>57527</td><td>38</td></tr>\n",
       "<tr><td>97185</td><td>45</td></tr>\n",
       "<tr><td>146033</td><td>52</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+------------------------+\n",
       "| likes|CAST(CBRT(likes) AS INT)|\n",
       "+------+------------------------+\n",
       "| 57527|                      38|\n",
       "| 97185|                      45|\n",
       "|146033|                      52|\n",
       "+------+------------------------+"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfYoutube.select('likes', F.cbrt('likes').cast('int')).limit(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Handling abnormality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Duplicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark; findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.enableHiveSupport().getOrCreate()\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>video_id</th><th>trending_date</th><th>channel_title</th><th>category_id</th><th>publish_time</th><th>views</th><th>likes</th><th>dislikes</th><th>comment_count</th><th>comments_disabled</th><th>ratings_disabled</th></tr>\n",
       "<tr><td>2kyS6SvSYSE</td><td>2017-11-14</td><td>CaseyNeistat</td><td>22</td><td>2017-11-13T17:13:...</td><td>748374</td><td>57527</td><td>2966</td><td>15954</td><td>False</td><td>False</td></tr>\n",
       "<tr><td>1ZAPwfrtAFY</td><td>2017-11-14</td><td>LastWeekTonight</td><td>24</td><td>2017-11-13T07:30:...</td><td>2418783</td><td>97185</td><td>6146</td><td>12703</td><td>False</td><td>False</td></tr>\n",
       "<tr><td>5qpjK5DgCt4</td><td>2017-11-14</td><td>Rudy Mancuso</td><td>23</td><td>2017-11-12T19:05:...</td><td>3191434</td><td>146033</td><td>5339</td><td>8181</td><td>False</td><td>False</td></tr>\n",
       "<tr><td>puqaWrEC7tY</td><td>2017-11-14</td><td>Good Mythical Mor...</td><td>24</td><td>2017-11-13T11:00:...</td><td>343168</td><td>10172</td><td>666</td><td>2146</td><td>False</td><td>False</td></tr>\n",
       "<tr><td>d380meD0W0M</td><td>2017-11-14</td><td>nigahiga</td><td>24</td><td>2017-11-12T18:01:...</td><td>2095731</td><td>132235</td><td>1989</td><td>17518</td><td>False</td><td>False</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------+-------------+--------------------+-----------+--------------------+-------+------+--------+-------------+-----------------+----------------+\n",
       "|   video_id|trending_date|       channel_title|category_id|        publish_time|  views| likes|dislikes|comment_count|comments_disabled|ratings_disabled|\n",
       "+-----------+-------------+--------------------+-----------+--------------------+-------+------+--------+-------------+-----------------+----------------+\n",
       "|2kyS6SvSYSE|   2017-11-14|        CaseyNeistat|         22|2017-11-13T17:13:...| 748374| 57527|    2966|        15954|            False|           False|\n",
       "|1ZAPwfrtAFY|   2017-11-14|     LastWeekTonight|         24|2017-11-13T07:30:...|2418783| 97185|    6146|        12703|            False|           False|\n",
       "|5qpjK5DgCt4|   2017-11-14|        Rudy Mancuso|         23|2017-11-12T19:05:...|3191434|146033|    5339|         8181|            False|           False|\n",
       "|puqaWrEC7tY|   2017-11-14|Good Mythical Mor...|         24|2017-11-13T11:00:...| 343168| 10172|     666|         2146|            False|           False|\n",
       "|d380meD0W0M|   2017-11-14|            nigahiga|         24|2017-11-12T18:01:...|2095731|132235|    1989|        17518|            False|           False|\n",
       "+-----------+-------------+--------------------+-----------+--------------------+-------+------+--------+-------------+-----------------+----------------+"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfYoutube = spark.read.csv('data/youtube_trending.csv', header=True)\n",
    "dfYoutube.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>category_id</th></tr>\n",
       "<tr><td>15</td></tr>\n",
       "<tr><td>29</td></tr>\n",
       "<tr><td>22</td></tr>\n",
       "<tr><td>28</td></tr>\n",
       "<tr><td>43</td></tr>\n",
       "<tr><td>27</td></tr>\n",
       "<tr><td>17</td></tr>\n",
       "<tr><td>26</td></tr>\n",
       "<tr><td>19</td></tr>\n",
       "<tr><td>23</td></tr>\n",
       "<tr><td>25</td></tr>\n",
       "<tr><td>24</td></tr>\n",
       "<tr><td>1</td></tr>\n",
       "<tr><td>20</td></tr>\n",
       "<tr><td>10</td></tr>\n",
       "<tr><td>2</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------+\n",
       "|category_id|\n",
       "+-----------+\n",
       "|         15|\n",
       "|         29|\n",
       "|         22|\n",
       "|         28|\n",
       "|         43|\n",
       "|         27|\n",
       "|         17|\n",
       "|         26|\n",
       "|         19|\n",
       "|         23|\n",
       "|         25|\n",
       "|         24|\n",
       "|          1|\n",
       "|         20|\n",
       "|         10|\n",
       "|          2|\n",
       "+-----------+"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep first observation only\n",
    "dfYoutube.select('category_id').drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Handling missing values\n",
    "Missing values in PySpark are represented by <code style='font-size:13px;'>null</code> or <code style='font-size:13px;'>nan</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark; findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.enableHiveSupport().getOrCreate()\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>product</th><th>price</th><th>stock</th></tr>\n",
       "<tr><td>Laptop</td><td>$1000</td><td>null</td></tr>\n",
       "<tr><td>Mouse</td><td>$20</td><td>100</td></tr>\n",
       "<tr><td>Headphone</td><td>$50</td><td>50</td></tr>\n",
       "<tr><td>USB</td><td>null</td><td>null</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------+-----+-----+\n",
       "|  product|price|stock|\n",
       "+---------+-----+-----+\n",
       "|   Laptop|$1000| null|\n",
       "|    Mouse|  $20|  100|\n",
       "|Headphone|  $50|   50|\n",
       "|      USB| null| null|\n",
       "+---------+-----+-----+"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "    ('Laptop', '$1000', None),\n",
    "    ('Mouse', '$20', 100),\n",
    "    ('Headphone', '$50', 50),\n",
    "    ('USB', None, None)\n",
    "]\n",
    "\n",
    "schema = ['product', 'price', 'stock']\n",
    "\n",
    "dfProduct = spark.createDataFrame(data, schema)\n",
    "dfProduct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>product</th><th>price</th><th>stock</th></tr>\n",
       "<tr><td>USB</td><td>null</td><td>null</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+-----+-----+\n",
       "|product|price|stock|\n",
       "+-------+-----+-----+\n",
       "|    USB| null| null|\n",
       "+-------+-----+-----+"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfProduct.filter('stock IS NULL and price IS NULL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>product</th><th>price</th><th>stock</th></tr>\n",
       "<tr><td>Mouse</td><td>$20</td><td>100</td></tr>\n",
       "<tr><td>Headphone</td><td>$50</td><td>50</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------+-----+-----+\n",
       "|  product|price|stock|\n",
       "+---------+-----+-----+\n",
       "|    Mouse|  $20|  100|\n",
       "|Headphone|  $50|   50|\n",
       "+---------+-----+-----+"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfProduct.dropna(subset=['stock'],how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>product</th><th>price</th><th>stock</th></tr>\n",
       "<tr><td>Laptop</td><td>$1000</td><td>0</td></tr>\n",
       "<tr><td>Mouse</td><td>$20</td><td>100</td></tr>\n",
       "<tr><td>Headphone</td><td>$50</td><td>50</td></tr>\n",
       "<tr><td>USB</td><td>100</td><td>0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------+-----+-----+\n",
       "|  product|price|stock|\n",
       "+---------+-----+-----+\n",
       "|   Laptop|$1000|    0|\n",
       "|    Mouse|  $20|  100|\n",
       "|Headphone|  $50|   50|\n",
       "|      USB|  100|    0|\n",
       "+---------+-----+-----+"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfProduct.fillna({\n",
    "    'price': 100,\n",
    "    'stock': 0\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*&#9829; By Quang Hung x Thuy Linh &#9829;*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
