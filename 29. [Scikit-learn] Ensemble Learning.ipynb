{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Ensemble Learning overview\n",
    "Classical Machine Learning algorithms are usually shown to be poor when handling real-world datasets. Models fit from these algorithms often suffer from two problems: high bias and high variance; such a model is called a *weak learner*. In this topic, we are going through some elegant techniques that combine multiple algorithms to form a powerful model, which produces an improved overall result. This is referred to generally as [Ensemble Learning](https://en.wikipedia.org/wiki/Ensemble_learning). Enemble Learning methods in fact have proved their effectiveness in many Machine Learing competitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Voting\n",
    "[Voting](https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier) (for classification) or [Averaging](https://scikit-learn.org/stable/modules/ensemble.html#voting-regressor) (for regression) is the simplest ensembling method. When doing voting for classification, there are two strategies can be applied: marjority voting on predicted results (hard voting) and taking argmax of the weighted average of predicted probabilities (soft voting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T09:36:46.798410Z",
     "iopub.status.busy": "2022-01-01T09:36:46.797956Z",
     "iopub.status.idle": "2022-01-01T09:36:46.804842Z",
     "shell.execute_reply": "2022-01-01T09:36:46.803425Z",
     "shell.execute_reply.started": "2022-01-01T09:36:46.798373Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.set_printoptions(precision=4, floatmode='maxprec')\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier, VotingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T09:31:43.188099Z",
     "iopub.status.busy": "2022-01-01T09:31:43.187857Z",
     "iopub.status.idle": "2022-01-01T09:31:43.199839Z",
     "shell.execute_reply": "2022-01-01T09:31:43.199180Z",
     "shell.execute_reply.started": "2022-01-01T09:31:43.188076Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X, y, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T09:47:25.941429Z",
     "iopub.status.busy": "2022-01-01T09:47:25.941159Z",
     "iopub.status.idle": "2022-01-01T09:47:25.945586Z",
     "shell.execute_reply": "2022-01-01T09:47:25.944826Z",
     "shell.execute_reply.started": "2022-01-01T09:47:25.941406Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf1 = SVC(probability=True)\n",
    "clf2 = LogisticRegression(solver='liblinear')\n",
    "clf3 = DecisionTreeClassifier()\n",
    "\n",
    "models = [clf1, clf2, clf3]\n",
    "base_models = [(i.__class__.__name__, i) for i in models]\n",
    "ensembler = VotingClassifier(base_models, voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T09:47:41.230030Z",
     "iopub.status.busy": "2022-01-01T09:47:41.229779Z",
     "iopub.status.idle": "2022-01-01T09:47:41.282840Z",
     "shell.execute_reply": "2022-01-01T09:47:41.282250Z",
     "shell.execute_reply.started": "2022-01-01T09:47:41.230009Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.8909 [SVC]\n",
      "AUC = 0.9230 [LogisticRegression]\n",
      "AUC = 0.8837 [DecisionTreeClassifier]\n",
      "AUC = 0.9455 [VotingClassifier]\n"
     ]
    }
   ],
   "source": [
    "for model in models + [ensembler]:\n",
    "    model = model.fit(XTrain, yTrain)\n",
    "    yPred = model.predict(XTest)\n",
    "    auc = roc_auc_score(yTest, yPred)\n",
    "    print(f'AUC = {auc:.4f} [{model.__class__.__name__}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Stacking\n",
    "[Stacking](https://scikit-learn.org/stable/modules/ensemble.html#stacked-generalization) technique organizes its members into two levels:\n",
    "- Level 1, a number of *base models* is fit to ther dataset. Build a new dataset where the values predicted by base models are input variables while the output variable remains the same.\n",
    "- Level 2, a *meta model* is train on the new dataset to get final prediction.\n",
    "\n",
    "The idea behind stacking is that each base model has an unique approach, it might discover some parts of the ground truth that other models do hot have. Combining them might utilize the their strengths and thus improve the overall quality. Note that Voting is a special case of Stacking, where the final combiner is a very simple model.\n",
    "\n",
    "In the implementation of Stacking, the base models are often selected *heterogeneously*, and the meta model is often a simple Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T09:29:57.923764Z",
     "iopub.status.busy": "2022-01-01T09:29:57.923443Z",
     "iopub.status.idle": "2022-01-01T09:29:58.776643Z",
     "shell.execute_reply": "2022-01-01T09:29:58.775773Z",
     "shell.execute_reply.started": "2022-01-01T09:29:57.923696Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.set_printoptions(precision=4, floatmode='maxprec')\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier, StackingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T09:42:16.576644Z",
     "iopub.status.busy": "2022-01-01T09:42:16.576356Z",
     "iopub.status.idle": "2022-01-01T09:42:16.589105Z",
     "shell.execute_reply": "2022-01-01T09:42:16.588294Z",
     "shell.execute_reply.started": "2022-01-01T09:42:16.576617Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X, y, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T09:47:18.619739Z",
     "iopub.status.busy": "2022-01-01T09:47:18.619327Z",
     "iopub.status.idle": "2022-01-01T09:47:18.626259Z",
     "shell.execute_reply": "2022-01-01T09:47:18.624984Z",
     "shell.execute_reply.started": "2022-01-01T09:47:18.619701Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf1 = KNeighborsClassifier()\n",
    "clf2 = GaussianNB()\n",
    "clf3 = SVC(probability=True)\n",
    "clf4 = LogisticRegression(solver='liblinear')\n",
    "clf5 = DecisionTreeClassifier()\n",
    "\n",
    "models = [clf1, clf2, clf3, clf4, clf5]\n",
    "base_models = [(i.__class__.__name__, i) for i in models]\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "ensembler = StackingClassifier(base_models, meta_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T09:47:19.560321Z",
     "iopub.status.busy": "2022-01-01T09:47:19.560056Z",
     "iopub.status.idle": "2022-01-01T09:47:19.734698Z",
     "shell.execute_reply": "2022-01-01T09:47:19.734072Z",
     "shell.execute_reply.started": "2022-01-01T09:47:19.560298Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.9373 [KNeighborsClassifier]\n",
      "AUC = 0.9368 [GaussianNB]\n",
      "AUC = 0.8909 [SVC]\n",
      "AUC = 0.9230 [LogisticRegression]\n",
      "AUC = 0.8966 [DecisionTreeClassifier]\n",
      "AUC = 0.9321 [StackingClassifier]\n"
     ]
    }
   ],
   "source": [
    "for model in models + [ensembler]:\n",
    "    model = model.fit(XTrain, yTrain)\n",
    "    yPred = model.predict(XTest)\n",
    "    auc = roc_auc_score(yTest, yPred)\n",
    "    print(f'AUC = {auc:.4f} [{model.__class__.__name__}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Bagging\n",
    "[Bootstrap Aggregating](https://scikit-learn.org/stable/modules/ensemble.html#bagging-meta-estimator) (Bagging) uses averaging/voting method over a number of *homogeneous* weak models in order to reduce variance. Specifically, Bagging is divided into two parts: [bootsrapping](<https://en.wikipedia.org/wiki/Bootstrapping_(statistics)>) and aggregating.\n",
    "\n",
    "- Boostrapping: The entire dataset is performed random sampling with replacement on both rows and columns. This outputs a number of bootstraps where each of them is different from the others.\n",
    "- Aggregating: after boostrap samples are generated, they are fit into the weak learners. All the model results will be combined by averaging (for regression) or voting (for classification).\n",
    "\n",
    "A Bagging ensembler operates as a committee that outperforms any individual weak model. This wonderful effect - *the wisdom of crowds* - can be explained that weak models protect each other from their individual errors. If the members share the same behaviors, they also make the same mistakes. Therefore, the low correlation between weak models is the key. Note that the Bagging method requires the initial sample to be large enough for the bootstrapping step to be statistical significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "Random Forest is the implementation of Bagging method on Decision Trees. It can be easily parallelized, does not requires too much hyperparameters tuning and has a decent prediction power. Random Forest is a very popular algorithm, before Boosting methods take the crown.\n",
    "\n",
    "[Scikit-learn's Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) has the following Bagging hyperparameters, beside the hyperparameters inherited from Decision Tree:\n",
    "\n",
    "Hyperparameter|Default|Meaning|Usage|\n",
    ":---|:---|:---|:---|\n",
    "`n_estimators`|`100`|The number of trees in the forest|Control the complexity of the algorithm. Try increasing this when<br>the model is underfitting, but it will take a longer training time.|\n",
    "`max_features`|`auto`|The ratio of features used in each tree|Lower values increase bias and reduce variance.|\n",
    "`max_samples`|`None`|The ratio of instances used in each tree|Lower values increase bias and reduce variance.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T10:02:54.944816Z",
     "iopub.status.busy": "2022-01-01T10:02:54.944554Z",
     "iopub.status.idle": "2022-01-01T10:02:54.948533Z",
     "shell.execute_reply": "2022-01-01T10:02:54.947582Z",
     "shell.execute_reply.started": "2022-01-01T10:02:54.944792Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.set_printoptions(precision=4, floatmode='maxprec')\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T09:46:34.523852Z",
     "iopub.status.busy": "2022-01-01T09:46:34.523566Z",
     "iopub.status.idle": "2022-01-01T09:46:34.536496Z",
     "shell.execute_reply": "2022-01-01T09:46:34.535736Z",
     "shell.execute_reply.started": "2022-01-01T09:46:34.523829Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X, y, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T10:02:56.608250Z",
     "iopub.status.busy": "2022-01-01T10:02:56.607847Z",
     "iopub.status.idle": "2022-01-01T10:02:56.651228Z",
     "shell.execute_reply": "2022-01-01T10:02:56.650188Z",
     "shell.execute_reply.started": "2022-01-01T10:02:56.608213Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.9325 [RandomForestClassifier]\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(\n",
    "    n_estimators=20,\n",
    "    min_samples_split=20,\n",
    "    max_depth=16,\n",
    "#     class_weight={0:1, 1:20}\n",
    ")\n",
    "\n",
    "clf = clf.fit(XTrain, yTrain)\n",
    "\n",
    "yPred = clf.predict(XTest)\n",
    "auc = roc_auc_score(yTest, yPred)\n",
    "\n",
    "print(f'AUC = {auc:.4f} [{clf.__class__.__name__}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T09:46:31.982784Z",
     "iopub.status.busy": "2022-01-01T09:46:31.982375Z",
     "iopub.status.idle": "2022-01-01T09:46:31.988612Z",
     "shell.execute_reply": "2022-01-01T09:46:31.987134Z",
     "shell.execute_reply.started": "2022-01-01T09:46:31.982746Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier, BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T09:46:34.523852Z",
     "iopub.status.busy": "2022-01-01T09:46:34.523566Z",
     "iopub.status.idle": "2022-01-01T09:46:34.536496Z",
     "shell.execute_reply": "2022-01-01T09:46:34.535736Z",
     "shell.execute_reply.started": "2022-01-01T09:46:34.523829Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X, y, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T09:46:51.897528Z",
     "iopub.status.busy": "2022-01-01T09:46:51.897257Z",
     "iopub.status.idle": "2022-01-01T09:46:51.901381Z",
     "shell.execute_reply": "2022-01-01T09:46:51.900333Z",
     "shell.execute_reply.started": "2022-01-01T09:46:51.897504Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model = LogisticRegression(solver='liblinear', class_weight={0:1, 1:10})\n",
    "ensembler = BaggingClassifier(base_model, 10, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T09:46:58.972643Z",
     "iopub.status.busy": "2022-01-01T09:46:58.972333Z",
     "iopub.status.idle": "2022-01-01T09:46:59.022197Z",
     "shell.execute_reply": "2022-01-01T09:46:59.021557Z",
     "shell.execute_reply.started": "2022-01-01T09:46:58.972614Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.8957 [LogisticRegression]\n",
      "AUC = 0.9048 [BaggingClassifier]\n"
     ]
    }
   ],
   "source": [
    "models = [base_model, ensembler]\n",
    "for model in models:\n",
    "    model = model.fit(XTrain, yTrain)\n",
    "    yPred = model.predict(XTest)\n",
    "    auc = roc_auc_score(yTest, yPred)\n",
    "    print(f'AUC = {auc:.4f} [{model.__class__.__name__}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Boosting\n",
    "[Boosting](<https://en.wikipedia.org/wiki/Boosting_(machine_learning)>) works in the same spirit as Bagging: it also build a group of *homogeneous* models to obtain a more powerful predictor. The difference is that Boosting trains weak models sequentially while Bagging perform the training independently. The idea behind Boosting is to fit models iteratively such that the training of each model depends on the previous ones. Using this strategy, badly handled observations in the earlier steps will be taken care better in the later steps. Since the Boosting method puts its efforts on important cases, we end up have a strong learner with lower bias.\n",
    "\n",
    "In applications, Boosting methods used on Decision Trees are so effective for tabular datasets and is widely used by top competitors. For the rest of this article, we will go through a bunch of interesting Boosting algorithms. To start off, this section discuss the first successful method in the Boosting family, [Adaptive Boosting](https://en.wikipedia.org/wiki/AdaBoost) (AdaBoost).\n",
    "\n",
    "AdaBoost was originally designed for binary classification problems. This method can be used to boost any algorithm, but Decision Tree is always the go-to choice. More specifically, Decision Trees used here are very shallow, they only have one root and two leaves, explaining why they are also called Decision Stumps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost\n",
    "AdaBoost takes the following inputs:\n",
    "- A dataset having $N$ observations $(\\mathbf{X},\\mathbf{y})=\\{(\\mathbf{x}_n,y_n)\\}_{n=1}^N$ where $y_n\\in\\{-1,1\\}$\n",
    "- The number of weak models, $T$\n",
    "- The learning rate, $\\eta$\n",
    "\n",
    "The algorithm:\n",
    "\n",
    "*Step 1.* Initialize the weight for each observation: $w_n^{(1)}=1/N$.\n",
    "\n",
    "*Step 2.* For $t=1,2,\\dots,T$:\n",
    "\n",
    "   - Train a weak model $\\hat{y}_n=f_t(\\mathbf{x}_n)$ that minimizes the sum of weights over misclassifications, represented by the error:\n",
    "   \n",
    "   $$\\displaystyle{\\epsilon_t=\\sum{w_n^{(t)}\\;\\left[\\hat{y}_n\\neq y_n\\right]}}$$\n",
    "\n",
    "   - Calculate $\\alpha_t$ the amount of say for the current weak classifier; deciding how much $f_t$ will contribute in the final prediction. This calculation rewards $f_t$ a very high influence if its total error is low and penalizes $f_t$ a negative influence for a high total error.\n",
    "   \n",
    "   $$\\displaystyle{\\alpha_t=\\frac{\\eta}{2}\\,\\ln{\\frac{1-\\epsilon_t}{\\epsilon_t}}}$$\n",
    "   \n",
    "   - Update sample weights for the next iteration so that: the weights of the correctly classied samples decrease $\\exp{(\\alpha_t)}$ times and the weights of misclassifications increase the same amount. Note that the term $-\\hat{y}_n y_n$ equals to $1$ if the prediction is correct and equals to $-1$ if the prediction is incorrect.\n",
    "   \n",
    "   $$w_n^{(t+1)}=w_n^{(t)}e^{(-\\hat{y}_n y_n)\\,\\alpha_t}$$\n",
    "   \n",
    "   - Normalize new weights so that they add up to $1$. This step is required to make the calculation of $\\alpha_{t+1}$ meaningful. At this step, some implementations resample the dataset so that the distribution of observations follows the newly calculated weights.\n",
    "\n",
    "*Step 3.* Build an additive strong model $F(\\mathbf{x})$ that performs weighted voting over $T$ weak learners; this is the output of the algorithm. The formula uses the notation $\\text{sign}(\\bullet)$, indicating the [sign function](https://en.wikipedia.org/wiki/Sign_function).\n",
    "\n",
    "$$F(\\mathbf{x})=\\text{sign}\\left(\\sum_{t=1}^T\\alpha_t f_t(\\mathbf{x})\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T17:20:21.621536Z",
     "iopub.status.busy": "2022-01-01T17:20:21.621168Z",
     "iopub.status.idle": "2022-01-01T17:20:22.069610Z",
     "shell.execute_reply": "2022-01-01T17:20:22.069006Z",
     "shell.execute_reply.started": "2022-01-01T17:20:21.621503Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(['seaborn', 'seaborn-whitegrid'])\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T17:34:14.925112Z",
     "iopub.status.busy": "2022-01-01T17:34:14.924770Z",
     "iopub.status.idle": "2022-01-01T17:34:15.159184Z",
     "shell.execute_reply": "2022-01-01T17:34:15.158475Z",
     "shell.execute_reply.started": "2022-01-01T17:34:14.925084Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 308,
       "width": 335
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eta = 0.2\n",
    "x = np.linspace(0.01, 0.99, 1000)\n",
    "y = eta * 1/2 * np.log(1/x - 1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.plot(x, y, 'k', label=fr'Learning rate = {eta}')\n",
    "ax.axis('scaled')\n",
    "ax.set_xlabel(r'Error, $\\epsilon_t$')\n",
    "ax.set_ylabel(r'Influence, $\\alpha_t$')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "[Scikit-learn's AdaBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) has the following hyperparameters:\n",
    "\n",
    "Hyperparameter|Default|Meaning|Usage|\n",
    ":-|:-|:-|:-|\n",
    "`base_estimator`|`None`|The algorithm to be boosted|\n",
    "`n_estimators`|`50`|The number of weak learners, $T$|\n",
    "`learning_rate`|`1`|The learning rate, $\\eta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T02:57:05.556257Z",
     "iopub.status.busy": "2022-01-02T02:57:05.555900Z",
     "iopub.status.idle": "2022-01-02T02:57:07.354431Z",
     "shell.execute_reply": "2022-01-02T02:57:07.353874Z",
     "shell.execute_reply.started": "2022-01-02T02:57:05.556190Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T02:57:07.355882Z",
     "iopub.status.busy": "2022-01-02T02:57:07.355667Z",
     "iopub.status.idle": "2022-01-02T02:57:07.371322Z",
     "shell.execute_reply": "2022-01-02T02:57:07.370793Z",
     "shell.execute_reply.started": "2022-01-02T02:57:07.355863Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X, y, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T17:09:22.934042Z",
     "iopub.status.busy": "2022-01-01T17:09:22.933504Z",
     "iopub.status.idle": "2022-01-01T17:09:22.939945Z",
     "shell.execute_reply": "2022-01-01T17:09:22.938177Z",
     "shell.execute_reply.started": "2022-01-01T17:09:22.934006Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model = DecisionTreeClassifier(max_depth=1)\n",
    "ensembler = AdaBoostClassifier(base_model, n_estimators=50, learning_rate=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T17:09:46.831315Z",
     "iopub.status.busy": "2022-01-01T17:09:46.831017Z",
     "iopub.status.idle": "2022-01-01T17:09:46.992571Z",
     "shell.execute_reply": "2022-01-01T17:09:46.991957Z",
     "shell.execute_reply.started": "2022-01-01T17:09:46.831287Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.9502 [AdaBoostClassifier]\n"
     ]
    }
   ],
   "source": [
    "models = [ensembler]\n",
    "for model in models:\n",
    "    model = model.fit(XTrain, yTrain)\n",
    "    yPred = model.predict(XTest)\n",
    "    auc = roc_auc_score(yTest, yPred)\n",
    "    print(f'AUC = {auc:.4f} [{model.__class__.__name__}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Gradient Boosting Machine\n",
    "[Grandient Boosting](https://en.wikipedia.org/wiki/Gradient_boosting) is another boosting strategy beside Adaptive Boosting. The idea of this method is mostly inspired by [Gradient Descent](https://en.wikipedia.org/wiki/Gradient_descent), thus the name Gradient Boosting. Just like other ensembling methods, this algorithm works best on Decision Trees and becomes the foundation for its modern variants such as XGBoost, LightGBM and CatBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. The algorithm\n",
    "Gradient Boosting Trees was originally designed for regression problems. The algorithm considers the following inputs:\n",
    "- A dataset having $N$ observations $(\\mathbf{X},\\mathbf{y})=\\{(\\mathbf{x}_n,y_n)\\}_{n=1}^N$\n",
    "- The number of weak models, $T$\n",
    "- The learning rate, $\\eta$\n",
    "- A [differentiable](https://en.wikipedia.org/wiki/Differentiable_function) loss function $L(y,F(\\mathbf{x}))$ ([MSE](https://en.wikipedia.org/wiki/Mean_squared_error) is a popular choice)\n",
    "\n",
    "The algorithm:\n",
    "\n",
    "*Step 1.* Initialize the prediction as a constant. Since this is the very first prediction and will be updated step-by-step, we denote this value $F_0({\\mathbf{x}})$. When the loss function is MSE, this value is nothing but the mean of $\\mathbf{y}$.\n",
    "\n",
    "$$F_0(\\mathbf{x})=\\underset\\gamma{\\arg\\min}\\sum_{n=1}^NL(y_n,\\gamma)$$\n",
    "\n",
    "*Step 2.* For $t=1$ to $T$:\n",
    "\n",
    "   - Compute the psuedo-residual $r_n^{(t)}$ equals to the derivative of the loss function with respect to the prediction of the iteration $t-1$. When MSE is used, this term is proportional to the actual residual, $y_n-F(\\mathbf{x}_n)$. Thus, we call it psuedo-residual for generalization, allowing plugging if different loss functions.\n",
    "   \n",
    "   $$r_n^{(t)}=-\\left[\\frac{\\partial L(y_n,F(\\mathbf{x}_n))}{\\partial F(\\mathbf{x}_n)}\\right]_{F(x)=F_{m-1}(x)}$$\n",
    "\n",
    "   - Fit a weak learner $f_t(\\mathbf{x})$ using the training set $\\{(\\mathbf{x}_n,r_n^{(t)})\\}_{n=1}^N$. This step results in a tree with $J_t$ leaf nodes; it means the input space is split into $J_t$ [disjoint](https://en.wikipedia.org/wiki/Disjoint_sets) regions, each region is denoted $R_j\\;(j=1,2,\\dots,J_t)$. Trees in this step is not restricted to be stumps as in AdaBoost.\n",
    "   \n",
    "   - Compute $\\gamma_j^{(t)}$, the predicted value for the model $f_t$. By using first-order [Taylor approximation](https://en.wikipedia.org/wiki/Taylor_series), it can be proved that $\\gamma_j^{(t)}$ is proportional to the negative gradient $r_n^{(t)}$. When MSE is chosen as the loss function, $\\gamma_j^{(t)}$ is the average residual in the leaf $R_j$. As $\\gamma_j^{(t)}$ is added to the final prediction $F$ at each iteration, this can be considered a Gradient Descent algorithm.\n",
    "   \n",
    "   $$\\gamma_j^{(t)}=\\underset\\gamma{\\arg\\min}\\sum_{\\mathbf{x}_n\\in R_j}{L(y_n,F_{t-1}(\\mathbf{x}_n)+\\gamma)}$$\n",
    "   \n",
    "   - Update the strong model $F_t$ by adding the current weak predictor scaled by the learning rate. The formula uses the [indicator notation](https://en.wikipedia.org/wiki/Indicator_function).\n",
    "   \n",
    "   $$F_t(x)=F_{t-1}(x)+\\eta\\sum_{j=1}^{J_t}{\\gamma_j^{(t)}\\mathbf{1}_{R_j}(x)}$$\n",
    "   \n",
    "*Step 3*. Take the last strong model as the final predictor: $F\\leftarrow F_t$. Note that in Gradient Boosting, the $t^{th}$ learner $F_t$ has taken into account all  weak learners up to the current iteration. Not like in Adaptive Boosting, the strong model is only built once all weak leaners was trained successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Implementation\n",
    "[Scikit-learn's Gradient Boosting](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html) considers the following hyperparameters (excluding the ones come from Decision Tree). Scikit-learn also introduces the [Histogram-based Gradient Boosting](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html) which is inspired by LightGBM and is much more faster than the original implementation.\n",
    "\n",
    "Hyperparameter|Default|Meaning|Usage|\n",
    ":---|:---|:---|:---|\n",
    "`loss`|`deviance` (classifification)<br>`squared_error` (regression)|The loss function||\n",
    "`n_estimators`|`100`|The number of boosting stages ($T$)||\n",
    "`learning_rate`|`0.1`|The learning rate ($\\eta$)|\n",
    "`subsample`|`1.0`|The ratio of instances used in each tree|Lower values increase bias and reduce variance|\n",
    "`max_features`|`None`|The ratio of features used in each tree|Lower values increase bias and reduce variance|\n",
    "`criterion`|`friedman_mse`|The mearsure quality of split||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T16:33:58.203250Z",
     "iopub.status.busy": "2022-01-04T16:33:58.202982Z",
     "iopub.status.idle": "2022-01-04T16:34:27.189526Z",
     "shell.execute_reply": "2022-01-04T16:34:27.188792Z",
     "shell.execute_reply.started": "2022-01-04T16:33:58.203226Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.set_printoptions(precision=4, floatmode='maxprec')\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier, HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T16:41:46.510412Z",
     "iopub.status.busy": "2022-01-04T16:41:46.510141Z",
     "iopub.status.idle": "2022-01-04T16:41:46.523752Z",
     "shell.execute_reply": "2022-01-04T16:41:46.522992Z",
     "shell.execute_reply.started": "2022-01-04T16:41:46.510389Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X, y, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T16:41:56.149265Z",
     "iopub.status.busy": "2022-01-04T16:41:56.149015Z",
     "iopub.status.idle": "2022-01-04T16:41:57.313333Z",
     "shell.execute_reply": "2022-01-04T16:41:57.312489Z",
     "shell.execute_reply.started": "2022-01-04T16:41:56.149243Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.9775 [GradientBoostingClassifier]\n",
      "AUC = 0.9455 [HistGradientBoostingClassifier]\n"
     ]
    }
   ],
   "source": [
    "clf1 = GradientBoostingClassifier()\n",
    "clf2 = HistGradientBoostingClassifier()\n",
    "models = [clf1, clf2]\n",
    "\n",
    "for model in models:\n",
    "    model = model.fit(XTrain, yTrain)\n",
    "    yPred = model.predict(XTest)\n",
    "    auc = roc_auc_score(yTest, yPred)\n",
    "    print(f'AUC = {auc:.4f} [{model.__class__.__name__}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. The algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T17:10:16.426324Z",
     "iopub.status.busy": "2022-01-04T17:10:16.425909Z",
     "iopub.status.idle": "2022-01-04T17:10:16.430661Z",
     "shell.execute_reply": "2022-01-04T17:10:16.429393Z",
     "shell.execute_reply.started": "2022-01-04T17:10:16.426279Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.set_printoptions(precision=4, floatmode='maxprec')\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier, XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T16:49:39.384331Z",
     "iopub.status.busy": "2022-01-04T16:49:39.383993Z",
     "iopub.status.idle": "2022-01-04T16:49:39.399052Z",
     "shell.execute_reply": "2022-01-04T16:49:39.398263Z",
     "shell.execute_reply.started": "2022-01-04T16:49:39.384300Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X, y, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T17:12:15.888140Z",
     "iopub.status.busy": "2022-01-04T17:12:15.887758Z",
     "iopub.status.idle": "2022-01-04T17:12:16.030266Z",
     "shell.execute_reply": "2022-01-04T17:12:16.028735Z",
     "shell.execute_reply.started": "2022-01-04T17:12:15.888097Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.9636 [XGBClassifier]\n"
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier(eval_metric='error', use_label_encoder=False)\n",
    "\n",
    "model = clf.fit(XTrain, yTrain)\n",
    "yPred = model.predict(XTest)\n",
    "auc = roc_auc_score(yTest, yPred)\n",
    "print(f'AUC = {auc:.4f} [{model.__class__.__name__}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. LightGBM\n",
    "[LightGBM](https://lightgbm.readthedocs.io/en/latest/) is an implementation of Gradient Boosting developed by Microsoft in order to deal with large datasets. According to [LightGBM paper](https://proceedings.neurips.cc/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf), *the main cost in GBDT lies in learning the decision trees, and the most time-consuming part in learning a decision tree is to find the best split points*. XGBoost has developed histogram-based split finding that reduces the complexity of the algorithm from $O(\\#instance \\times \\#feature)$ to $O(\\#bin \\times \\#feature)$ where $\\#bin\\ll \\#instance$, which outperforms other implementations in terms of memory consumption.\n",
    "\n",
    "However, XGBoost still does not meet the satisfactory of scalability when working on large datasets. To improve the performance of previous implementations, LightGBM introduces two novels techniques, *Gradient-based One-Side Sampling* (GOSS) for reducing data instances and *Exclusive Feature Bundling* (EFB) for reducing data dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. The algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient-based one-side sampling\n",
    "As the purpose of GOSS is to smartly sample data, it requires sample weights to achieve this. Althought Gradient Boosting does not have any native weight as in Adaptive Boosting, we can use residuals (generally gradients) as pseudo-weights. The GOSS algorithm is implemented right before the training of each weak learner and is described as follows.\n",
    "\n",
    "*Input:*\n",
    "- A dataset of $N$ observations and their corresponding gradients computed from the most recent predictor\n",
    "- $a$ - the sampling ratio of large gradient data and $b$ - the sampling ratio of small gradient data ($a+b$ should not be greater than $1$)\n",
    "\n",
    "*Step 1:* Sort (in descending order) the observations by the absolute values of their gradients and select top $\\lfloor aN \\rfloor$ observations. This under-trained set is what the training of the next tree should focus on.\n",
    "\n",
    "*Step 2:* Perform random sampling $\\lfloor bN \\rfloor$ observations from the rest of the data. In order to compensate the information losses that affect data distribution, each instance in this well-trained set is amplified by a constant $\\frac{1-a}{b}>1$ when calculating information gain in the next tree.\n",
    "\n",
    "*Step 3:* Combine the under-trained set and the well-trained set above to form a single set to be used in learning the Decision Tree. By using this technique, *we put more focus on the under-trained instances without changing the original data distribution by much*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclusive feature bundling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T17:07:47.251126Z",
     "iopub.status.busy": "2022-01-04T17:07:47.250865Z",
     "iopub.status.idle": "2022-01-04T17:07:47.255182Z",
     "shell.execute_reply": "2022-01-04T17:07:47.254212Z",
     "shell.execute_reply.started": "2022-01-04T17:07:47.251103Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.set_printoptions(precision=4, floatmode='maxprec')\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T16:49:39.384331Z",
     "iopub.status.busy": "2022-01-04T16:49:39.383993Z",
     "iopub.status.idle": "2022-01-04T16:49:39.399052Z",
     "shell.execute_reply": "2022-01-04T16:49:39.398263Z",
     "shell.execute_reply.started": "2022-01-04T16:49:39.384300Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X, y, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T17:08:05.866463Z",
     "iopub.status.busy": "2022-01-04T17:08:05.866166Z",
     "iopub.status.idle": "2022-01-04T17:08:06.058369Z",
     "shell.execute_reply": "2022-01-04T17:08:06.057268Z",
     "shell.execute_reply.started": "2022-01-04T17:08:05.866437Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.9364 [LGBMClassifier]\n"
     ]
    }
   ],
   "source": [
    "clf = LGBMClassifier()\n",
    "\n",
    "model = clf.fit(XTrain, yTrain)\n",
    "yPred = model.predict(XTest)\n",
    "auc = roc_auc_score(yTest, yPred)\n",
    "print(f'AUC = {auc:.4f} [{model.__class__.__name__}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. The algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordered boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T17:31:55.947470Z",
     "iopub.status.busy": "2022-01-04T17:31:55.947140Z",
     "iopub.status.idle": "2022-01-04T17:31:55.951243Z",
     "shell.execute_reply": "2022-01-04T17:31:55.950374Z",
     "shell.execute_reply.started": "2022-01-04T17:31:55.947440Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.set_printoptions(precision=4, floatmode='maxprec')\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T16:49:39.384331Z",
     "iopub.status.busy": "2022-01-04T16:49:39.383993Z",
     "iopub.status.idle": "2022-01-04T16:49:39.399052Z",
     "shell.execute_reply": "2022-01-04T16:49:39.398263Z",
     "shell.execute_reply.started": "2022-01-04T16:49:39.384300Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X, y, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T16:55:47.098732Z",
     "iopub.status.busy": "2022-01-04T16:55:47.098230Z",
     "iopub.status.idle": "2022-01-04T16:55:49.820022Z",
     "shell.execute_reply": "2022-01-04T16:55:49.818822Z",
     "shell.execute_reply.started": "2022-01-04T16:55:47.098684Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.9636 [CatBoostClassifier]\n"
     ]
    }
   ],
   "source": [
    "clf = CatBoostClassifier()\n",
    "\n",
    "model = clf.fit(XTrain, yTrain, logging_level='Silent')\n",
    "yPred = model.predict(XTest)\n",
    "auc = roc_auc_score(yTest, yPred)\n",
    "print(f'AUC = {auc:.4f} [{model.__class__.__name__}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- [Scikit-learn] [Ensemble methods](https://scikit-learn.org/stable/modules/ensemble.html)\n",
    "- [XGBoost] [Introduction to Boosted Trees](https://xgboost.readthedocs.io/en/stable/tutorials/model.html)\n",
    "- [Towards Data Science] [Ensemble methods: bagging, boosting and stacking](https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205)\n",
    "\n",
    "\n",
    "- [Paper] [A short introduction to Boosting](http://www.cs.columbia.edu/~jebara/6772/papers/IntroToBoosting.pdf)\n",
    "- [Paper] [XGBoost: A scalable tree boosting system](https://arxiv.org/pdf/1603.02754.pdf)\n",
    "- [Paper] [LightGBM: A highly efficient Gradient Boosting Decision Tree](https://proceedings.neurips.cc/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf)\n",
    "- [Paper] [CatBoost: Unbiased Boosting with categorical features](https://arxiv.org/pdf/1706.09516.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "**Signing**:\n",
    "- $O_{value}$: Output value\n",
    "- $\\lambda$ : Regulaziration parameter\n",
    "- $\\gamma$: Tree complexity parameter\n",
    "- $\\eta$: Learning rate\n",
    "- Gradient ($g$): First derivative of loss function\n",
    "- Hessian ($h$): Second derivative of loss function\n",
    "- Residual :$r$\n",
    "- Number of residual: $N_r$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The idea and mathematical behind xgboost\n",
    "\n",
    "The first step of fitting XGboost to the training data is making the initial prediction $p_0$ (default is `0.5` for both regression and classification). Like GBM, XGboost fit a tree to the residual of each observation but each tree in XGboost is unique. XGB build a tree which try to minimize the equation:\n",
    "$$\\sum_{i=1}^{n}L(y_i,p_{i}^0+O_{value}) + \\frac{1}{2}\\lambda*{O^2_{value}}  \\space \\mbox{(1)}$$\n",
    "with $L$ is *loss function* and ($\\frac{1}{2}\\lambda*{O^2_{value}}$) is *regularization term*.\\\n",
    "The goal of XGB is finding the optimal output value to minimize the equation $(1)$.\n",
    "\n",
    "To make an Xgboost tree, firstly we calculate the residuals of each obs different to initial prediction then making similariry score for the root:\n",
    "$$\\mbox{Similariry Score} = \\frac{(\\sum gradient)^2}{\\sum hessian + \\lambda}$$\n",
    "Similarity score tell us the similarity between residual of observations, if residuals is different, they cancel out the others so that the similarity score will be small. And $\\lambda$ is the regularization parameter, it's intend to reduce the prediction's sensitivity to individual observations and then prevent overfitting. When $\\lambda$ increase, the similarity score wil be decrease - the amount of decrease is inversely proportional to the number of residual in the node.\\\n",
    "After having the similarity for the root, we find an optimal split point for the tree. We'll choose one threshold to split the obs and then calculating similarity score for each node. To quantify how much better the leaves similar residual than the root, we calculate the gain:\n",
    "$$\\mbox{gain} = \\mbox{left}_{similarity} + \\mbox{right}_{similarity} - \\mbox{root}_{similarity}$$\n",
    "\n",
    "We can compare the gain of this thresold to the others and the threshold which made the largest gain will be chosen. Continue building tree with other feature until getting the maximum split.\n",
    "\n",
    "Now we have the full tree, to prune the tree, we use $\\gamma$ parameter. If $gain - \\gamma < 0$, we prune that leave.\n",
    "\n",
    "Next step is find the output for each leaf of the tree. To do that, we derivate the equation $(1)$ and we get the formular for optimal output:\n",
    "$$O_{value}=\\frac{-\\sum gradient}{\\sum hessian + \\lambda}$$\n",
    "\n",
    "The larger $\\lambda$, the closer output value to 0.\\\n",
    "Finally, we use the output value plus learning rate to make the new prediction:\n",
    "$$p_0 + \\sum_{m=1}^{m}\\eta * O_{value}$$\n",
    "\n",
    "Like GBM, the process go on with the next tree which is build based on residual of previous tree. And ending by reaching the smallest residual or maximum tree.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application in regression\n",
    "\n",
    "In regression, XGB use loss function just like GBM:\n",
    "$$L(y_i,p_i) = \\frac{1}{2}(y_i-p_i)^2$$\n",
    "\n",
    "Then gradient and hessian of loss function is :\n",
    "$g_i = -(y_i-p_i)$ and $h_i = 1$\n",
    "\n",
    "Replace to $O_{value}$ and similarity score we will have:\n",
    "$$O_{value} = \\frac{\\sum r}{N_r + \\lambda}$$\n",
    "\n",
    "$$\\mbox{similarity score} = \\frac{\\sum r^2}{N_{r} + \\lambda} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application in classification\n",
    "\n",
    "In classification, the loss function is the negative likelihood:\n",
    "$$L(y_i,p_i) = -[y_i*log(p_i) + (1-y_i)*log(1-p_i)]$$\n",
    "Then gradient and hessian of loss function is: \n",
    "$g_i = -(y_i-p_i)$ and $h_i = p_i*(1-p_i)$\n",
    "\n",
    "Replace we have:\n",
    "$$O_{value} = \\frac{\\sum r}{N_r + \\lambda}$$\n",
    "\n",
    "$$\\mbox{similarity score} = \\frac{\\sum r^2}{cover+ \\lambda} $$\n",
    "with $Cover = \\sum h_i= \\sum[\\mbox{previous prob}*(1-\\mbox{previous prob})]$ \n",
    "\n",
    "Despite making probability as a new prediction, we predict $log(odds)$ of prediction then convert to probability (because ouput value is the $log(odds)$ now):\n",
    "\n",
    "$$log(odds) prediction = log(\\frac{p_0}{1-p_0}) + \\eta*O_{value}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM\n",
    "\n",
    "LightGBM is a gradient boosting framework which use tree based learning algorithm. \n",
    "\n",
    "The reason why lightgbm became powerful are:\n",
    "1. Optimization in accuracy: \n",
    "- LigthGBM uses *leaf_wise* stategy to grow the tree vertically. It will choose the leaf with max delta  loss to grow. \n",
    "- Optimal split for category feature. Other boosting can only use one-hot encoding for category feature but lightGBM can treat feature values equally although values in numeric (i.e: gender 0-unknow, 1-man, 2-woman)\n",
    "2.  Optimization in speed and memory usage: \n",
    "- LightGBM uses histogram-based algorithms, which bucket continuous feature values into discrete bins. Algo will find the best split between bins.\n",
    "- LightGBM uses Gradient-based one side sampling (GOSS) method. By usual, subsample process is done by taking random sample from dataset. But GOSS not only perform a faster way to do this but also keep distribution of the data. The instances with larger gradients (under-trained), contribute a lot more to the tree building process so we keep all instances with large gradient, but to prevent changing the distribution, we need to perform random sampling on instances with small gradients. Assume we have \n",
    "$n$ data instances, if we keep $a$ instances with large gradients and randomly samples $x$% $(n-a)$ instances with small gradients, we have the sampled data with size $a+ x$% $*(n-a)$. \n",
    "3. Sparse Optimization:\n",
    "- LightGBM handle sparse data by using Exclusive feature bundling (EFB). EFB is a technique that uses a greedy algorithm to combine (or bundle) these mutually exclusive (means never take non-zero in the same time) into a single feature and thus reduce the dimensionality.\n",
    "4. Optimization in Distributed Learning:\n",
    "- Distributed learning allows the use of multiple machines to produce a single model.\n",
    "- Feature parallel: Data had split vertically, each worker handle a subset of feature to find the best split on local feature set then they communicate to others to get the best one. \n",
    "- Data parallel: Data had split horizontally, each worker will construct the local histograms then merge them to make global histogram of the data and find the best split on global histogram. \n",
    "- Voting parallel: It is the special case of data parallel when communication cost is constant.\n",
    "\n",
    "||Data is small| Data is large\n",
    "|:--|:--|:--\n",
    "**Feature  is small**|Feature parallel|Data parallel|\n",
    "**Feature is large**|Feaure parallel|Voting parallel|\n",
    "\n",
    "LightGBM also supports GPU learning. The disadvantage of LGBM is it can easily overfit with small dataset and can't be use with one-hot encoding because of optimal category feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation\n",
    "\n",
    "*Reference*: [LightGBM docs](https://lightgbm.readthedocs.io/en/latest/Parameters.html)\\\n",
    "There are several parameters in LGBM which separate into groups:\n",
    "1. Core parameters\n",
    "- task: Type of task which perform on your data. Default is `train`, common is `train`/`predict`\n",
    "- object: Type of problem - regression, binary or multiclass. Default is `regression`.\n",
    "- boosting: Type of algorithms. Default is `GDBT`. Common value is `GOSS`.\n",
    "- num_iterations: Number of interation. Default is 100\n",
    "- learning_rate: Default is `0.1`. Common values are `0.001`, `0.003`\n",
    "- num_leaves: Max number of leaves in full tree. Default is `31`\n",
    "- tree_learner: type of distributed learning. Default is `serial`. Common values are: `feature`,`data`,`voting`.\n",
    "- device_type: `cpu` or `gpu`. GPU can perform better than CPU\n",
    "- data: path of training data\n",
    "- valid: path of validation data. Support multiple validation data\n",
    "2. Learning control parameter\n",
    "- max_depth: The maximum depth of tree. Default is `-1` means no limit.\n",
    "- min_data_in_leaf: The minimum observations a leaf. Default is `20`\n",
    "- feature_fraction: Subset of feature in each tree. Default is `1.0`\n",
    "- bagging_fraction: Subsample data. Default is `1.0`\n",
    "- early_stopping_round: Model will stop training if one metric of one validation data doesnt improve in last early_stopping_round rounds. Default is `0`.\n",
    "- lambda: lambda specifies regularization (L1/L2). Default is `0.0`\n",
    "- min_gain_to_split:the minimal gain to perform split. Default is `0.0`\n",
    "- max_cat_threshold:Limit number of split points considered for categorical features. Default is `32`\n",
    "3. IO parameter\n",
    "- max_bin: Max number of bins that feature values will be bucketed in. Default is `255`\n",
    "- categorical_feature: used to specify categorical features. Fill with index or name of columns.\n",
    "- is_enable_sparse: used to enable/disable sparse optimization. Default is `true`\n",
    "- enable_bundle: used EFB to bunlding feature. Default is `true`\n",
    "- weight_column: used to specify the weight column. Fill with index or name of column\n",
    "- save_binary: if true, LightGBM will save the dataset (including validation data) to a binary file. This speed ups the data loading for the next time. Default is `true`\n",
    "4. Metric parameter\n",
    "- metric: metric(s) to be evaluated on the evaluation set(s). Default is `\"\"`. Common values are `mae`,`mse`,`auc`,`binary_logloss`,..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Bad_customer</th>\n",
       "      <th>credit_balance_percent</th>\n",
       "      <th>age</th>\n",
       "      <th>num_of_group1_pastdue</th>\n",
       "      <th>debt_ratio</th>\n",
       "      <th>income</th>\n",
       "      <th>num_of_loans</th>\n",
       "      <th>num_of_times_late_90days</th>\n",
       "      <th>num_of_estate_loans</th>\n",
       "      <th>num_of_group2_pastdue</th>\n",
       "      <th>num_of_dependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.766127</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0.802982</td>\n",
       "      <td>9120.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.957151</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121876</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.658180</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.085113</td>\n",
       "      <td>3042.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.233810</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036050</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.907239</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024926</td>\n",
       "      <td>63588.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Bad_customer  credit_balance_percent  age  num_of_group1_pastdue  \\\n",
       "0      0             1                0.766127   45                      2   \n",
       "1      1             0                0.957151   40                      0   \n",
       "2      2             0                0.658180   38                      1   \n",
       "3      3             0                0.233810   30                      0   \n",
       "4      4             0                0.907239   49                      1   \n",
       "\n",
       "   debt_ratio   income  num_of_loans  num_of_times_late_90days  \\\n",
       "0    0.802982   9120.0            13                         0   \n",
       "1    0.121876   2600.0             4                         0   \n",
       "2    0.085113   3042.0             2                         1   \n",
       "3    0.036050   3300.0             5                         0   \n",
       "4    0.024926  63588.0             7                         0   \n",
       "\n",
       "   num_of_estate_loans  num_of_group2_pastdue  num_of_dependents  \n",
       "0                    6                      0                2.0  \n",
       "1                    0                      0                1.0  \n",
       "2                    0                      0                0.0  \n",
       "3                    0                      0                0.0  \n",
       "4                    1                      0                0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit = pd.read_excel('data/credit_scoring.xlsx')\n",
    "credit = credit.dropna().reset_index()\n",
    "credit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = credit.Bad_customer.values\n",
    "x = credit.drop(columns='Bad_customer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = lgbm.Dataset(x_train, label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'learning_rate': [0.001],\n",
    "    'boosting_type': 'goss',\n",
    "    'objective': [1],\n",
    "    'criterion':['friedman_mse']\n",
    "#     'min_sample_split':[10,5,2]  \n",
    "}\n",
    "\n",
    "gbm = GradientBoostingClassifier()\n",
    "gbm = GridSearchCV(gbm, params, cv=3)\n",
    "gbm = gbm.fit(x_train, y_train)\n",
    "gbm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = gbm.predict(x_train)\n",
    "y_test_pred = gbm.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*&#9829; By Quang Hung x Thuy Linh &#9829;*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
